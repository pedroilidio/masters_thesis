@article{adiyeke2022semisupervised,
title = {Semi-Supervised Extensions of Multi-Task Tree Ensembles},
author = {Ad{\i}yeke, Esra and Baydo{\u g}an, Mustafa G{\~A}{\P}k{\c c}e},
year = {2022},
month = mar,
journal = {Pattern Recognition},
volume = {123},
pages = {108393},
publisher = {Elsevier BV},
doi = {10.1016/j.patcog.2021.108393},
url = {https://doi.org/10.1016%2Fj.patcog.2021.108393},
annotation = {2 citations (Crossref) [2023-08-29]},
file = {/home/pd/Zotero/storage/YIM5FJ8E/Adıyeke and Baydoğan - 2022 - Semi-supervised extensions of multi-task tree ense.pdf}
}

@misc{agarwal2023mdi,
title = {{{MDI}}+},
subtitle = {{{A Flexible Random Forest-Based Feature Importance Framework}}},
shorttitle = {{{MDI}}+},
author = {Agarwal, Abhineet and Kenney, Ana M. and Tan, Yan Shuo and Tang, Tiffany M. and Yu, Bin},
year = {2023},
month = jul,
number = {arXiv:2307.01932},
eprint = {2307.01932},
primaryclass = {cs, stat},
url = {http://arxiv.org/abs/2307.01932},
urldate = {13 Jan. 2024},
abstract = {Mean decrease in impurity (MDI) is a popular feature importance measure for random forests (RFs). We show that the MDI for a feature \$X\_k\$ in each tree in an RF is equivalent to the unnormalized \$R\^{}2\$ value in a linear regression of the response on the collection of decision stumps that split on \$X\_k\$. We use this interpretation to propose a flexible feature importance framework called MDI+. Specifically, MDI+ generalizes MDI by allowing the analyst to replace the linear regression model and \$R\^{}2\$ metric with regularized generalized linear models (GLMs) and metrics better suited for the given data structure. Moreover, MDI+ incorporates additional features to mitigate known biases of decision trees against additive or smooth models. We further provide guidance on how practitioners can choose an appropriate GLM and metric based upon the Predictability, Computability, Stability framework for veridical data science. Extensive data-inspired simulations show that MDI+ significantly outperforms popular feature importance measures in identifying signal features. We also apply MDI+ to two real-world case studies on drug response prediction and breast cancer subtype classification. We show that MDI+ extracts well-established predictive genes with significantly greater stability compared to existing feature importance measures. All code and models are released in a full-fledged python package on Github.},
archiveprefix = {arxiv},
keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning,Statistics - Methodology},
file = {/home/pd/Zotero/storage/CDI8ZX8H/Agarwal et al. - 2023 - MDI+ A Flexible Random Forest-Based Feature Impor.pdf;/home/pd/Zotero/storage/37SPKG68/2307.html}
}

@article{alaimo2013drug,
title = {Drug--Target Interaction Prediction through Domain-Tuned Network-Based Inference},
author = {Alaimo, Salvatore and Pulvirenti, Alfredo and Giugno, Rosalba and Ferro, Alfredo},
year = {2013},
journal = {Bioinformatics},
volume = {29},
number = {16},
pages = {2004--2008},
publisher = {Oxford University Press}
}

@article{ali1996error,
title = {Error Reduction through Learning Multiple Descriptions},
author = {Ali, Kamal M. and Pazzani, Michael J.},
year = {1996},
month = sep,
journal = {Machine Learning},
volume = {24},
number = {3},
pages = {173--202},
issn = {0885-6125, 1573-0565},
doi = {10.1007/BF00058611},
url = {http://link.springer.com/10.1007/BF00058611},
urldate = {23 Sep. 2023},
langid = {english},
annotation = {99 citations (Crossref) [2023-09-23]},
file = {/home/pd/Zotero/storage/TAHILZY7/Ali and Pazzani - 1996 - Error reduction through learning multiple descript.pdf}
}

@inproceedings{alves2023semisupervised,
title = {Semi-{{Supervised Hybrid Predictive Bi-Clustering Trees}} for {{Drug-Target Interaction Prediction}}},
booktitle = {Proceedings [...]},
author = {Alves, Andre and Ilidio, Pedro and Cerri, Ricardo},
year = {2023},
pages = {1163--1170},
publisher = {ACM/SIGAPP},
address = {Tallinn},
organization = {SYMPOSIUM ON APPLIED COMPUTING, 38, 2023, Tallinn}
}

@inproceedings{amasyali2011comparison,
title = {Comparison of Single and Ensemble Classifiers in Terms of Accuracy and Execution Time},
booktitle = {Proceedings [...]},
author = {Amasyali, M. F. and Ersoy, O. K.},
year = {2011},
month = jun,
pages = {470--474},
publisher = {IEEE},
address = {Istanbul},
doi = {10.1109/INISTA.2011.5946119},
url = {http://ieeexplore.ieee.org/document/5946119/},
urldate = {23 Sep. 2023},
isbn = {978-1-61284-919-5},
organization = {INTERNATIONAL SYMPOSIUM ON INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (INISTA), 2011, Istanbul}
}

@article{amit1997shape,
title = {Shape {{Quantization}} and {{Recognition}} with {{Randomized Trees}}},
author = {Amit, Yali and Geman, Donald},
year = {1997},
month = oct,
journal = {Neural Computation},
volume = {9},
number = {7},
pages = {1545--1588},
issn = {0899-7667, 1530-888X},
doi = {10.1162/neco.1997.9.7.1545},
url = {https://direct.mit.edu/neco/article/9/7/1545-1588/6116},
urldate = {23 Sep. 2023},
abstract = {We explore a new approach to shape recognition based on a virtually infinite family of binary features (queries) of the image data, designed to accommodate prior information about shape invariance and regularity. Each query corresponds to a spatial arrangement of several local topographic codes (or tags), which are in themselves too primitive and common to be informative about shape. All the discriminating power derives from relative angles and distances among the tags. The important attributes of the queries are a natural partial ordering corresponding to increasing structure and complexity; semi-invariance, meaning that most shapes of a given class will answer the same way to two queries that are successive in the ordering; and stability, since the queries are not based on distinguished points and substructures. No classifier based on the full feature set can be evaluated, and it is impossible to determine a priori which arrangements are informative. Our approach is to select informative features and build tree classifiers at the same time by inductive learning. In effect, each tree provides an approximation to the full posterior where the features chosen depend on the branch that is traversed. Due to the number and nature of the queries, standard decision tree construction based on a fixed-length feature vector is not feasible. Instead we entertain only a small random sample of queries at each node, constrain their complexity to increase with tree depth, and grow multiple trees. The terminal nodes are labeled by estimates of the corresponding posterior distribution over shape classes. An image is classified by sending it down every tree and aggregating the resulting distributions. The method is applied to classifying handwritten digits and synthetic linear and nonlinear deformations of three hundred [Formula: see text] symbols. State-of-the-art error rates are achieved on the National Institute of Standards and Technology database of digits. The principal goal of the experiments on [Formula: see text] symbols is to analyze invariance, generalization error and related issues, and a comparison with artificial neural networks methods is presented in this context. [Figure: see text]},
langid = {english},
annotation = {777 citations (Crossref) [2023-09-23]}
}

@book{asratian1998bipartite,
title = {Bipartite Graphs and Their Applications},
author = {Asratian, Armen S and Denley, Tristan MJ and H{\"a}ggkvist, Roland},
year = {1998},
series = {Cambridge Tracts in Mathematics},
volume = {131},
publisher = {Cambridge university press},
address = {Cambridge}
}

@article{bagherian2020machine,
title = {Machine Learning Approaches and Databases for Prediction of Drug--Target Interaction},
subtitle = {A Survey Paper},
author = {Bagherian, Maryam and Sabeti, Elyas and Wang, Kai and Sartor, Maureen A. and {Nikolovska-Coleska}, Zaneta and Najarian, Kayvan},
year = {2020},
month = jan,
journal = {Briefings in Bioinformatics},
volume = {22},
number = {1},
pages = {247--269},
publisher = {Oxford University Press (OUP)},
doi = {10.1093/bib/bbz157},
url = {https://doi.org/10.1093%2Fbib%2Fbbz157},
annotation = {157 citations (Crossref) [2023-08-29]},
file = {/home/pd/Zotero/storage/7M2BDEL5/Bagherian et al. - 2020 - Machine learning approaches and databases for pred.pdf}
}

@article{ban2019nrlmf,
title = {{{NRLMF}}{\textbackslash}upbeta},
subtitle = {{{Beta-distribution-rescored}} Neighborhood Regularized Logistic Matrix Factorization for Improving the Performance of Drug--Target Interaction Prediction},
author = {Ban, Tomohiro and Ohue, Masahito and Akiyama, Yutaka},
year = {2019},
month = jul,
journal = {Biochemistry and Biophysics Reports},
volume = {18},
pages = {100615},
publisher = {Elsevier BV},
doi = {10.1016/j.bbrep.2019.01.008},
url = {https://doi.org/10.1016%2Fj.bbrep.2019.01.008},
annotation = {9 citations (Crossref) [2023-08-29]}
}

@article{bekker2020learning,
title = {Learning from Positive and Unlabeled Data},
subtitle = {A Survey},
shorttitle = {Learning from Positive and Unlabeled Data},
author = {Bekker, Jessa and Davis, Jesse},
year = {2020},
month = apr,
journal = {Machine Learning},
volume = {109},
number = {4},
pages = {719--760},
issn = {1573-0565},
doi = {10.1007/s10994-020-05877-5},
url = {https://doi.org/10.1007/s10994-020-05877-5},
urldate = {24 Jan. 2024},
abstract = {Learning from positive and unlabeled data or PU learning is the setting where a learner only has access to positive examples and unlabeled data. The assumption is that the unlabeled data can contain both positive and negative examples. This setting has attracted increasing interest within the machine learning literature as this type of data naturally arises in applications such as medical diagnosis and knowledge base completion. This article provides a survey of the current state of the art in PU learning. It proposes seven key research questions that commonly arise in this field and provides a broad overview of how the field has tried to address them.},
langid = {english},
keywords = {68T05,Classification,PU learning,Weakly supervised learning},
annotation = {215 citations (Crossref) [2024-01-24]},
file = {/home/pd/Zotero/storage/V4MIVCVY/Bekker and Davis - 2020 - Learning from positive and unlabeled data a surve.pdf}
}

@article{benavoli2016should,
title = {Should {{We Really Use Post-Hoc Tests Based}} on {{Mean-Ranks}}?},
author = {Benavoli, Alessio and Corani, Giorgio and Mangili, Francesca},
year = {2016},
journal = {Journal of Machine Learning Research},
volume = {17},
number = {5},
pages = {1--10},
issn = {1533-7928},
url = {http://jmlr.org/papers/v17/benavoli16a.html},
urldate = {12 Jan. 2024},
abstract = {The statistical comparison of multiple algorithms over multiple data sets is fundamental in machine learning. This is typically carried out by the Friedman test. When the Friedman test rejects the null hypothesis, multiple comparisons are carried out to establish which are the significant differences among algorithms. The multiple comparisons are usually performed using the mean-ranks test. The aim of this technical note is to discuss the inconsistencies of the mean-ranks post-hoc test with the goal of discouraging its use in machine learning as well as in medicine, psychology, etc.. We show that the outcome of the mean-ranks test depends on the pool of algorithms originally included in the experiment. In other words, the outcome of the comparison between algorithms A {$A$} and B {$B$} depends also on the performance of the other algorithms included in the original experiment. This can lead to paradoxical situations. For instance the difference between A {$A$} and B {$B$} could be declared significant if the pool comprises algorithms C,D,E {$C$} , {$D$} , {$E$} and not significant if the pool comprises algorithms F,G,H {$F$} , {$G$} , {$H$} . To overcome these issues, we suggest instead to perform the multiple comparison using a test whose outcome only depends on the two algorithms being compared, such as the sign-test or the Wilcoxon signed-rank test.},
file = {/home/pd/Zotero/storage/ESJNESRI/Benavoli et al. - 2016 - Should We Really Use Post-Hoc Tests Based on Mean-.pdf}
}

@article{benjamini1995controlling,
title = {Controlling the {{False Discovery Rate}}},
subtitle = {{{A Practical}} and {{Powerful Approach}} to {{Multiple Testing}}},
shorttitle = {Controlling the {{False Discovery Rate}}},
author = {Benjamini, Yoav and Hochberg, Yosef},
year = {1995},
journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
volume = {57},
number = {1},
pages = {289--300},
issn = {2517-6161},
doi = {10.1111/j.2517-6161.1995.tb02031.x},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2517-6161.1995.tb02031.x},
urldate = {17 Mar. 2024},
abstract = {The common approach to the multiplicity problem calls for controlling the familywise error rate (FWER). This approach, though, has faults, and we point out a few. A different approach to problems of multiple significance testing is presented. It calls for controlling the expected proportion of falsely rejected hypotheses --- the false discovery rate. This error rate is equivalent to the FWER when all hypotheses are true but is smaller otherwise. Therefore, in problems where the control of the false discovery rate rather than that of the FWER is desired, there is potential for a gain in power. A simple sequential Bonferronitype procedure is proved to control the false discovery rate for independent test statistics, and a simulation study shows that the gain in power is substantial. The use of the new procedure and the appropriateness of the criterion are illustrated with examples.},
copyright = {{\copyright} 1995 Royal Statistical Society},
langid = {english},
keywords = {bonferroni-type procedures,familywise error rate,multiple-comparison procedures,p-values},
annotation = {23462 citations (Crossref) [2024-03-17]},
file = {/home/pd/Zotero/storage/H64LU37E/j.2517-6161.1995.tb02031.html}
}

@article{bleakley2009supervised,
title = {Supervised Prediction of Drug--Target Interactions Using Bipartite Local Models},
author = {Bleakley, Kevin and Yamanishi, Yoshihiro},
year = {2009},
month = jul,
journal = {Bioinformatics},
volume = {25},
number = {18},
pages = {2397--2403},
issn = {1367-4803},
doi = {10.1093/bioinformatics/btp433},
url = {https://doi.org/10.1093/bioinformatics/btp433},
annotation = {454 citations (Crossref) [2023-08-29]}
}

@article{bonissone2010fuzzy,
title = {A Fuzzy Random Forest},
author = {Bonissone, Piero and Cadenas, Jos{\'e} M. and Carmen Garrido, M. and {Andr{\'e}s D{\'i}az-Valladares}, R.},
year = {2010},
month = sep,
journal = {International Journal of Approximate Reasoning},
volume = {51},
number = {7},
pages = {729--747},
issn = {0888-613X},
doi = {10.1016/j.ijar.2010.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0888613X10000435},
urldate = {16 Mar. 2024},
abstract = {When individual classifiers are combined appropriately, a statistically significant increase in classification accuracy is usually obtained. Multiple classifier systems are the result of combining several individual classifiers. Following Breiman's methodology, in this paper a multiple classifier system based on a ``forest'' of fuzzy decision trees, i.e., a fuzzy random forest, is proposed. This approach combines the robustness of multiple classifier systems, the power of the randomness to increase the diversity of the trees, and the flexibility of fuzzy logic and fuzzy sets for imperfect data management. Various combination methods to obtain the final decision of the multiple classifier system are proposed and compared. Some of them are weighted combination methods which make a weighting of the decisions of the different elements of the multiple classifier system (leaves or trees). A comparative study with several datasets is made to show the efficiency of the proposed multiple classifier system and the various combination methods. The proposed multiple classifier system exhibits a good accuracy classification, comparable to that of the best classifiers when tested with conventional data sets. However, unlike other classifiers, the proposed classifier provides a similar accuracy when tested with imperfect datasets (with missing and fuzzy values) and with datasets with noise.},
keywords = {Combination methods,Fuzzy decision tree,Fuzzy sets,Random forest},
annotation = {126 citations (Crossref) [2024-03-16]},
file = {/home/pd/Zotero/storage/IXQ5N5PN/S0888613X10000435.html}
}

@inproceedings{boyd2013area,
title = {Area under the {{Precision-Recall Curve}}},
subtitle = {{{Point Estimates}} and {{Confidence Intervals}}},
shorttitle = {Area under the {{Precision-Recall Curve}}},
booktitle = {Machine {{Learning}} and {{Knowledge Discovery}} in {{Databases}}},
author = {Boyd, Kendrick and Eng, Kevin H. and Page, C. David},
editor = {Blockeel, Hendrik and Kersting, Kristian and Nijssen, Siegfried and {\v Z}elezn{\'y}, Filip},
year = {2013},
series = {Lecture {{Notes}} in {{Computer Science}}},
pages = {451--466},
publisher = {Springer},
address = {Berlin},
doi = {10.1007/978-3-642-40994-3_29},
abstract = {The area under the precision-recall curve (AUCPR) is a single number summary of the information in the precision-recall (PR) curve. Similar to the receiver operating characteristic curve, the PR curve has its own unique properties that make estimating its enclosed area challenging. Besides a point estimate of the area, an interval estimate is often required to express magnitude and uncertainty. In this paper we perform a computational analysis of common AUCPR estimators and their confidence intervals. We find both satisfactory estimates and invalid procedures and we recommend two simple intervals that are robust to a variety of assumptions.},
isbn = {978-3-642-40994-3},
langid = {english},
keywords = {Average Precision,Bias Ratio,Markov Logic Network,Receiver Operating Character,Roswell Park Cancer Institute},
organization = {MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES, 2013, Berlin},
file = {/home/pd/Zotero/storage/RNSY39NB/Boyd et al. - 2013 - Area under the Precision-Recall Curve Point Estim.pdf}
}

@book{breiman1984classification,
title = {Classification and Regression Trees},
author = {Breiman, Leo and Friedman, Jerome and Olshen, R. A. and Ston, Charles J.},
year = {1984},
edition = {First Edition},
publisher = {Routledge},
address = {New York},
isbn = {978-1-315-13947-0},
file = {/home/pd/Zotero/storage/VYMTC7E8/Classification and Regression Trees (Wadsw - Leo Breiman.epub}
}

@article{breiman1996bagging,
title = {Bagging Predictors},
author = {Breiman, Leo},
year = {1996},
month = aug,
journal = {Machine Learning},
volume = {24},
number = {2},
pages = {123--140},
issn = {1573-0565},
doi = {10.1007/BF00058655},
url = {https://doi.org/10.1007/BF00058655},
urldate = {18 Mar. 2024},
abstract = {Bagging predictors is a method for generating multiple versions of a predictor and using these to get an aggregated predictor. The aggregation averages over the versions when predicting a numerical outcome and does a plurality vote when predicting a class. The multiple versions are formed by making bootstrap replicates of the learning set and using these as new learning sets. Tests on real and simulated data sets using classification and regression trees and subset selection in linear regression show that bagging can give substantial gains in accuracy. The vital element is the instability of the prediction method. If perturbing the learning set can cause significant changes in the predictor constructed, then bagging can improve accuracy.},
langid = {english},
keywords = {Aggregation,Averaging,Bootstrap,Combining},
annotation = {13430 citations (Crossref) [2024-03-18]},
file = {/home/pd/Zotero/storage/UM52ZBPY/Breiman - 1996 - Bagging predictors.pdf}
}

@article{breiman2001random,
title = {Random Forests},
author = {Breiman, Leo},
year = {2001},
journal = {Machine learning},
volume = {45},
pages = {5--32},
publisher = {Springer}
}

@article{brohee2011unraveling,
title = {Unraveling Networks of Co-Regulated Genes on the Sole Basis of Genome Sequences},
author = {Broh{\'e}e, Sylvain and Janky, Rekin's and {Abdel-Sater}, Fadi and Vanderstocken, Gilles and Andre, Bruno and Van Helden, Jacques},
year = {2011},
journal = {Nucleic acids research},
volume = {39},
number = {15},
pages = {6340--6358},
publisher = {Oxford University Press}
}

@article{brown2005diversity,
title = {Diversity Creation Methods},
subtitle = {A Survey and Categorisation},
shorttitle = {Diversity Creation Methods},
author = {Brown, Gavin and Wyatt, Jeremy and Harris, Rachel and Yao, Xin},
year = {2005},
month = mar,
journal = {Information Fusion},
volume = {6},
number = {1},
pages = {5--20},
issn = {15662535},
doi = {10.1016/j.inffus.2004.04.004},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1566253504000375},
urldate = {23 Sep. 2023},
langid = {english},
annotation = {668 citations (Crossref) [2023-09-23]},
file = {/home/pd/Zotero/storage/RWLSPCTY/Brown et al. - 2005 - Diversity creation methods a survey and categoris.pdf}
}

@book{chapelle2006semisupervised,
title = {Semi-Supervised Learning},
editor = {Chapelle, Olivier and Sch{\"o}lkopf, Bernhard and Zien, Alexander},
year = {2006},
series = {Adaptive Computation and Machine Learning},
publisher = {MIT Press},
address = {Cambridge},
isbn = {978-0-262-03358-9},
langid = {english},
lccn = {Q325.75 .S42 2006},
keywords = {Supervised learning (Machine learning)},
annotation = {OCLC: ocm64898359},
file = {/home/pd/Zotero/storage/C8KDYWQS/Chapelle et al. - 2006 - Semi-supervised learning.pdf}
}

@inproceedings{chen2016xgboost,
title = {{{XGBoost}}},
subtitle = {{{A Scalable Tree Boosting System}}},
shorttitle = {{{XGBoost}}},
booktitle = {Proceedings [...]},
author = {Chen, Tianqi and Guestrin, Carlos},
year = {2016},
month = aug,
pages = {785--794},
publisher = {ACM/SIGKDD},
address = {New York},
doi = {10.1145/2939672.2939785},
url = {https://dl.acm.org/doi/10.1145/2939672.2939785},
urldate = {15 Mar. 2024},
abstract = {Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems.},
isbn = {978-1-4503-4232-2},
keywords = {large-scale machine learning},
organization = {INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, 22, 2016, New York},
file = {/home/pd/Zotero/storage/87YL5UCL/Chen and Guestrin - 2016 - XGBoost A Scalable Tree Boosting System.pdf}
}

@article{chen2018machine,
title = {Machine {{Learning}} for {{Drug-Target Interaction Prediction}}},
author = {Chen, Ruolan and Liu, Xiangrong and Jin, Shuting and Lin, Jiawei and Liu, Juan},
year = {2018},
month = aug,
journal = {Molecules},
volume = {23},
number = {9},
pages = {2208},
publisher = {MDPI AG},
doi = {10.3390/molecules23092208},
url = {https://doi.org/10.3390%2Fmolecules23092208},
annotation = {137 citations (Crossref) [2023-08-29]},
file = {/home/pd/Zotero/storage/G4SCZ433/Chen et al. - 2018 - Machine Learning for Drug-Target Interaction Predi.pdf}
}

@article{chua2006identifying,
title = {Identifying Transcription Factor Functions and Targets by Phenotypic Activation},
author = {Chua, Gordon and Morris, Quaid D and Sopko, Richelle and Robinson, Mark D and Ryan, Owen and Chan, Esther T and Frey, Brendan J and Andrews, Brenda J and Boone, Charles and Hughes, Timothy R},
year = {2006},
journal = {Proceedings of the National Academy of Sciences},
volume = {103},
number = {32},
pages = {12045--12050},
publisher = {National Acad Sciences}
}

@article{cock2009biopython,
title = {Biopython},
subtitle = {Freely Available {{Python}} Tools for Computational Molecular Biology and Bioinformatics},
author = {Cock, Peter JA and Antao, Tiago and Chang, Jeffrey T and Chapman, Brad A and Cox, Cymon J and Dalke, Andrew and Friedberg, Iddo and Hamelryck, Thomas and Kauff, Frank and Wilczynski, Bartek and others},
year = {2009},
journal = {Bioinformatics},
volume = {25},
number = {11},
pages = {1422},
publisher = {Oxford University Press}
}

@article{consortium2019uniprot,
title = {{{UniProt}}},
subtitle = {A Worldwide Hub of Protein Knowledge},
author = {Consortium, UniProt},
year = {2019},
journal = {Nucleic acids research},
volume = {47},
number = {D1},
pages = {D506--D515},
publisher = {Oxford University Press}
}

@book{cormen2022introduction,
title = {Introduction to Algorithms},
author = {Cormen, Thomas H and Leiserson, Charles E and Rivest, Ronald L and Stein, Clifford},
year = {2022},
edition = {Fourth Edition},
publisher = {MIT press},
address = {Cambridge},
isbn = {978-0-262-04630-5},
langid = {english},
file = {/home/pd/Zotero/storage/BDIF8AKY/Introduction.to.Algorithms.4th.Leiserson.Stein.Rivest.Cormen.MIT.Press.9780262046305.EBooksWorld.ir.pdf}
}

@article{crammer2001algorithmic,
title = {On the Algorithmic Implementation of Multiclass Kernel-Based Vector Machines},
author = {Crammer, Koby and Singer, Yoram},
year = {2001},
journal = {Journal of machine learning research},
volume = {2},
number = {Dec},
pages = {265--292},
url = {https://www.jmlr.org/papers/volume2/crammer01a/crammer01a.pdf},
urldate = {16 Mar. 2024},
file = {/home/pd/Zotero/storage/RQNTHJ9H/Crammer and Singer - 2001 - On the algorithmic implementation of multiclass ke.pdf}
}

@inproceedings{davis2006relationship,
title = {The Relationship between {{Precision-Recall}} and {{ROC}} Curves},
booktitle = {Proceedings [...]},
author = {Davis, Jesse and Goadrich, Mark},
year = {2006},
month = jun,
pages = {233--240},
publisher = {ACM},
address = {New York},
doi = {10.1145/1143844.1143874},
url = {https://dl.acm.org/doi/10.1145/1143844.1143874},
urldate = {24 Oct. 2023},
abstract = {Receiver Operator Characteristic (ROC) curves are commonly used to present results for binary decision problems in machine learning. However, when dealing with highly skewed datasets, Precision-Recall (PR) curves give a more informative picture of an algorithm's performance. We show that a deep connection exists between ROC space and PR space, such that a curve dominates in ROC space if and only if it dominates in PR space. A corollary is the notion of an achievable PR curve, which has properties much like the convex hull in ROC space; we show an efficient algorithm for computing this curve. Finally, we also note differences in the two types of curves are significant for algorithm design. For example, in PR space it is incorrect to linearly interpolate between points. Furthermore, algorithms that optimize the area under the ROC curve are not guaranteed to optimize the area under the PR curve.},
isbn = {978-1-59593-383-6},
organization = {INTERNATIONAL CONFERENCE ON MACHINE LEARNING, 23, 2006, New York},
file = {/home/pd/Zotero/storage/EL8EBTQQ/Davis and Goadrich - 2006 - The relationship between Precision-Recall and ROC .pdf}
}

@article{davis2011comprehensive,
title = {Comprehensive Analysis of Kinase Inhibitor Selectivity},
author = {Davis, Mindy I and Hunt, Jeremy P and Herrgard, Sanna and Ciceri, Pietro and Wodicka, Lisa M and Pallares, Gabriel and Hocker, Michael and Treiber, Daniel K and Zarrinkar, Patrick P},
year = {2011},
journal = {Nature biotechnology},
volume = {29},
number = {11},
pages = {1046--1051},
publisher = {Nature Publishing Group US New York}
}

@article{dehghan2023tripletmultidti,
title = {{{TripletMultiDTI}}},
subtitle = {{{Multimodal Representation Learning}} in {{Drug-Target Interaction Prediction}} with {{Triplet Loss Function}}},
author = {Dehghan, Alireza and Razzaghi, Parvin and Abbasi, Karim and Gharaghani, Sajjad},
year = {2023},
month = jun,
journal = {Expert Systems with Applications},
pages = {120754},
publisher = {Elsevier BV},
doi = {10.1016/j.eswa.2023.120754},
url = {https://doi.org/10.1016%2Fj.eswa.2023.120754},
keywords = {deep learning},
annotation = {2 citations (Crossref) [2023-08-29]}
}

@article{demsar2006statistical,
title = {Statistical Comparisons of Classifiers over Multiple Data Sets},
author = {Dem{\v s}ar, Janez},
year = {2006},
journal = {The Journal of Machine learning research},
volume = {7},
pages = {1--30},
publisher = {JMLR. org},
url = {https://www.jmlr.org/papers/volume7/demsar06a/demsar06a.pdf},
urldate = {17 Mar. 2024},
file = {/home/pd/Zotero/storage/KXZERZ7N/Demšar - 2006 - Statistical comparisons of classifiers over multip.pdf}
}

@incollection{dietterich2000ensemble,
title = {Ensemble {{Methods}} in {{Machine Learning}}},
booktitle = {Multiple {{Classifier Systems}}},
author = {Dietterich, Thomas G.},
editor = {Goos, Gerhard and Hartmanis, Juris and Van Leeuwen, Jan},
year = {2000},
series = {Lecture Notes in Computer Science},
volume = {1857},
pages = {1--15},
publisher = {Springer Berlin Heidelberg},
address = {Heidelberg},
doi = {10.1007/3-540-45014-9_1},
url = {http://link.springer.com/10.1007/3-540-45014-9_1},
urldate = {23 Sep. 2023},
isbn = {978-3-540-67704-8 978-3-540-45014-6},
file = {/home/pd/Zotero/storage/5GLMGMJV/Dietterich - 2000 - Ensemble Methods in Machine Learning.pdf}
}

@article{ding2014similaritybased,
title = {Similarity-Based Machine Learning Methods for Predicting Drug--Target Interactions},
subtitle = {A Brief Review},
author = {Ding, Hao and Takigawa, Ichigaku and Mamitsuka, Hiroshi and Zhu, Shanfeng},
year = {2014},
journal = {Briefings in bioinformatics},
volume = {15},
number = {5},
pages = {734--747},
publisher = {Oxford University Press}
}

@article{duchi2011adaptive,
title = {Adaptive {{Subgradient Methods}} for {{Online Learning}} and {{Stochastic Optimization}}},
author = {Duchi, John and Hazan, Elad and Singer, Yoram},
year = {2011},
journal = {Journal of Machine Learning Research},
volume = {12},
number = {61},
pages = {2121--2159},
issn = {1533-7928},
url = {http://jmlr.org/papers/v12/duchi11a.html},
urldate = {15 Nov. 2023},
abstract = {We present a new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning. Metaphorically, the adaptation allows us to find needles in haystacks in the form of very predictive but rarely seen features. Our paradigm stems from recent advances in stochastic optimization and online learning which employ proximal functions to control the gradient steps of the algorithm. We describe and analyze an apparatus for adaptively modifying the proximal function, which significantly simplifies setting a learning rate and results in regret guarantees that are provably as good as the best proximal function that can be chosen in hindsight. We give several efficient algorithms for empirical risk minimization problems with common and important regularization functions and domain constraints. We experimentally study our theoretical analysis and show that adaptive subgradient methods outperform state-of-the-art, yet non-adaptive, subgradient algorithms.},
file = {/home/pd/Zotero/storage/H5HPC3VY/Duchi et al. - 2011 - Adaptive Subgradient Methods for Online Learning a.pdf}
}

@article{ezzat2019computational,
title = {Computational Prediction of Drug--Target Interactions Using Chemogenomic Approaches},
subtitle = {An Empirical Survey},
shorttitle = {Computational Prediction of Drug--Target Interactions Using Chemogenomic Approaches},
author = {Ezzat, Ali and Wu, Min and Li, Xiao-Li and Kwoh, Chee-Keong},
year = {2019},
month = jul,
journal = {Briefings in Bioinformatics},
volume = {20},
number = {4},
pages = {1337--1357},
issn = {1477-4054},
doi = {10.1093/bib/bby002},
url = {https://doi.org/10.1093/bib/bby002},
urldate = {31 Oct. 2023},
abstract = {Computational prediction of drug--target interactions (DTIs) has become an essential task in the drug discovery process. It narrows down the search space for interactions by suggesting potential interaction candidates for validation via wet-lab experiments that are well known to be expensive and time-consuming. In this article, we aim to provide a comprehensive overview and empirical evaluation on the computational DTI prediction techniques, to act as a guide and reference for our fellow researchers. Specifically, we first describe the data used in such computational DTI prediction efforts. We then categorize and elaborate the state-of-the-art methods for predicting DTIs. Next, an empirical comparison is performed to demonstrate the prediction performance of some representative methods under different scenarios. We also present interesting findings from our evaluation study, discussing the advantages and disadvantages of each method. Finally, we highlight potential avenues for further enhancement of DTI prediction performance as well as related research directions.},
annotation = {156 citations (Crossref) [2023-10-31]},
file = {/home/pd/Zotero/storage/9T9QPRYD/Ezzat et al. - 2019 - Computational prediction of drug–target interactio.pdf;/home/pd/Zotero/storage/XYRLVQ42/4824712.html}
}

@article{faith2007largescale,
title = {Large-Scale Mapping and Validation of {{Escherichia}} Coli Transcriptional Regulation from a Compendium of Expression Profiles},
author = {Faith, Jeremiah J and Hayete, Boris and Thaden, Joshua T and Mogno, Ilaria and Wierzbowski, Jamey and Cottarel, Guillaume and Kasif, Simon and Collins, James J and Gardner, Timothy S},
year = {2007},
journal = {PLoS biology},
volume = {5},
number = {1},
pages = {e8},
publisher = {Public Library of Science San Francisco, USA}
}

@article{fawagreh2014random,
title = {Random Forests},
subtitle = {From Early Developments to Recent Advancements},
shorttitle = {Random Forests},
author = {Fawagreh, Khaled and Gaber, Mohamed Medhat and Elyan, Eyad},
year = {2014},
month = dec,
journal = {Systems Science \& Control Engineering},
volume = {2},
number = {1},
pages = {602--609},
issn = {2164-2583},
doi = {10.1080/21642583.2014.956265},
url = {http://www.tandfonline.com/doi/abs/10.1080/21642583.2014.956265},
urldate = {23 Sep. 2023},
langid = {english},
annotation = {301 citations (Crossref) [2023-09-23]},
file = {/home/pd/Zotero/storage/IPLHPLU2/Fawagreh et al. - 2014 - Random forests from early developments to recent .pdf}
}

@book{fernandez2018learning,
title = {Learning from {{Imbalanced Data Sets}}},
author = {Fern{\'a}ndez, Alberto and Garc{\'i}a, Salvador and Galar, Mikel and Prati, Ronaldo C. and Krawczyk, Bartosz and Herrera, Francisco},
year = {2018},
publisher = {Springer International Publishing},
address = {Cham},
doi = {10.1007/978-3-319-98074-4},
url = {http://link.springer.com/10.1007/978-3-319-98074-4},
urldate = {18 Oct. 2023},
isbn = {978-3-319-98073-7 978-3-319-98074-4},
langid = {english},
file = {/home/pd/Zotero/storage/UUJBV3PB/Fernández et al. - 2018 - Learning from Imbalanced Data Sets.pdf;/home/pd/Zotero/storage/WNT34FXM/Alberto Fernández, Salvador García, Mikel Galar, Ronaldo C. Prati, Bartosz Krawczyk, Francisco Herrera - Learning from Imbalanced Data Sets-Springer International Publishing (2018).pdf;/home/pd/Zotero/storage/WU3BPVAT/Alberto Fernández_ Salvador García_ Mikel Galar_ Ronaldo C. Prati_ Bartosz Krawczyk_ Francisco Herrera - Learning from Imbalanced Data Sets-Springer International Publishing.epub}
}

@inproceedings{flach2015precisionrecallgain,
title = {Precision-{{Recall-Gain Curves}}},
subtitle = {{{PR Analysis Done Right}}},
shorttitle = {Precision-{{Recall-Gain Curves}}},
booktitle = {Proceedings [...]},
author = {Flach, Peter and Kull, Meelis},
year = {2015},
publisher = {Curran Associates, Inc.},
address = {Montreal},
url = {https://proceedings.neurips.cc/paper_files/paper/2015/hash/33e8075e9970de0cfea955afd4644bb2-Abstract.html},
urldate = {08 Nov. 2023},
organization = {ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS, 28, 2015, Montreal},
file = {/home/pd/Zotero/storage/HZ8P6HT6/Flach and Kull - 2015 - Precision-Recall-Gain Curves PR Analysis Done Rig.pdf}
}

@article{frankish2021gencode,
title = {{{GENCODE}} 2021},
author = {Frankish, Adam and Diekhans, Mark and Jungreis, Irwin and Lagarde, Julien and Loveland, Jane E and Mudge, Jonathan M and Sisu, Cristina and Wright, James C and Armstrong, Joel and Barnes, If and others},
year = {2021},
journal = {Nucleic acids research},
volume = {49},
number = {D1},
pages = {D916--D923},
publisher = {Oxford University Press}
}

@article{fu2022mvgcn,
title = {{{MVGCN}}},
subtitle = {Data Integration through Multi-View Graph Convolutional Network for Predicting Links in Biomedical Bipartite Networks},
shorttitle = {{{MVGCN}}},
author = {Fu, Haitao and Huang, Feng and Liu, Xuan and Qiu, Yang and Zhang, Wen},
year = {2022},
month = jan,
journal = {Bioinformatics},
volume = {38},
number = {2},
pages = {426--434},
issn = {1367-4803},
doi = {10.1093/bioinformatics/btab651},
url = {https://doi.org/10.1093/bioinformatics/btab651},
urldate = {23 Nov. 2023},
abstract = {There are various interaction/association bipartite networks in biomolecular systems. Identifying unobserved links in biomedical bipartite networks helps to understand the underlying molecular mechanisms of human complex diseases and thus benefits the diagnosis and treatment of diseases. Although a great number of computational methods have been proposed to predict links in biomedical bipartite networks, most of them heavily depend on features and structures involving the bioentities in one specific bipartite network, which limits the generalization capacity of applying the models to other bipartite networks. Meanwhile, bioentities usually have multiple features, and how to leverage them has also been challenging.In this study, we propose a novel multi-view graph convolution network (MVGCN) framework for link prediction in biomedical bipartite networks. We first construct a multi-view heterogeneous network (MVHN) by combining the similarity networks with the biomedical bipartite network, and then perform a self-supervised learning strategy on the bipartite network to obtain node attributes as initial embeddings. Further, a neighborhood information aggregation (NIA) layer is designed for iteratively updating the embeddings of nodes by aggregating information from inter- and intra-domain neighbors in every view of the MVHN. Next, we combine embeddings of multiple NIA layers in each view, and integrate multiple views to obtain the final node embeddings, which are then fed into a discriminator to predict the existence of links. Extensive experiments show MVGCN performs better than or on par with baseline methods and has the generalization capacity on six benchmark datasets involving three typical tasks.Source code and data can be downloaded from https://github.com/fuhaitao95/MVGCN.Supplementary data are available at Bioinformatics online.},
annotation = {31 citations (Crossref) [2023-11-23]},
file = {/home/pd/Zotero/storage/4JHJHT7G/Fu et al. - 2022 - MVGCN data integration through multi-view graph c.pdf;/home/pd/Zotero/storage/BD3TCWWD/6367769.html}
}

@misc{gaussian,
title = {Gaussian Interaction Profile Kernels for Predicting Drug--Target Interaction {\textbar} {{Bioinformatics}} {\textbar} {{Oxford Academic}}},
url = {https://academic.oup.com/bioinformatics/article/27/21/3036/216840},
urldate = {18 Nov. 2023},
file = {/home/pd/Zotero/storage/2SJJ22K3/supmat.pdf;/home/pd/Zotero/storage/WQE9DH3A/Gaussian interaction profile kernels for predictin.pdf;/home/pd/Zotero/storage/I3QSSJE4/216840.html}
}

@article{geurts2006extremely,
title = {Extremely Randomized Trees},
author = {Geurts, Pierre and Ernst, Damien and Wehenkel, Louis},
year = {2006},
journal = {Machine learning},
volume = {63},
pages = {3--42},
publisher = {Springer},
file = {/home/pd/Zotero/storage/3SPLNMXA/Geurts et al. - 2006 - Extremely randomized trees.pdf}
}

@article{griffiths-jones2006mirbase,
title = {{{miRBase}}},
subtitle = {{{microRNA}} Sequences, Targets and Gene Nomenclature},
author = {{GRIFFITHS-JONES,}, Sam and Grocock, Russell J and Van Dongen, Stijn and Bateman, Alex and Enright, Anton J},
year = {2006},
journal = {Nucleic acids research},
volume = {34},
number = {suppl\_1},
pages = {D140--D144},
publisher = {Oxford University Press}
}

@article{grinsztajn2022why,
title = {Why Do Tree-Based Models Still Outperform Deep Learning on Typical Tabular Data?},
author = {Grinsztajn, Leo and Oyallon, Edouard and Varoquaux, Gael},
year = {2022},
month = dec,
journal = {Advances in Neural Information Processing Systems},
volume = {35},
pages = {507--520},
url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/0378c7692da36807bdec87ab043cdadc-Abstract-Datasets_and_Benchmarks.html},
urldate = {15 Mar. 2024},
langid = {english},
file = {/home/pd/Zotero/storage/S6D3ZEPV/Grinsztajn et al. - 2022 - Why do tree-based models still outperform deep lea.pdf}
}

@article{hand2009measuring,
title = {Measuring Classifier Performance},
subtitle = {A~Coherent Alternative to the Area under the {{ROC}} Curve},
shorttitle = {Measuring Classifier Performance},
author = {Hand, David J.},
year = {2009},
month = oct,
journal = {Machine Learning},
volume = {77},
number = {1},
pages = {103--123},
issn = {1573-0565},
doi = {10.1007/s10994-009-5119-5},
url = {https://doi.org/10.1007/s10994-009-5119-5},
urldate = {31 Oct. 2023},
abstract = {The area under the ROC curve (AUC) is a very widely used measure of performance for classification and diagnostic rules. It has the appealing property of being objective, requiring no subjective input from the user. On the other hand, the AUC has disadvantages, some of which are well known. For example, the AUC can give potentially misleading results if ROC curves cross. However, the AUC also has a much more serious deficiency, and one which appears not to have been previously recognised. This is that it is fundamentally incoherent in terms of misclassification costs: the AUC uses different misclassification cost distributions for different classifiers. This means that using the AUC is equivalent to using different metrics to evaluate different classification rules. It is equivalent to saying that, using one classifier, misclassifying a class 1~point is p~times as serious as misclassifying a class 0~point, but, using another classifier, misclassifying a class 1~point is P~times as serious, where p{$\neq$}P. This is nonsensical because the relative severities of different kinds of misclassifications of individual points is a property of the problem, not the classifiers which happen to have been chosen. This property is explored in detail, and a simple valid alternative to the AUC is proposed.},
langid = {english},
keywords = {AUC,Classification,Cost,Error rate,Loss,Misclassification rate,ROC curves,Sensitivity,Specificity},
annotation = {626 citations (Crossref) [2023-10-30]},
file = {/home/pd/Zotero/storage/WQBRK3I6/Hand - 2009 - Measuring classifier performance a coherent alter.pdf}
}

@article{hao2017predicting,
title = {Predicting Drug-Target Interactions by Dual-Network Integrated Logistic Matrix Factorization},
author = {Hao, Ming and Bryant, Stephen H and Wang, Yanli},
year = {2017},
journal = {Scientific reports},
volume = {7},
number = {1},
pages = {40376},
publisher = {Nature Publishing Group UK London}
}

@article{hao2019opensource,
title = {Open-Source Chemogenomic Data-Driven Algorithms for Predicting Drug--Target Interactions},
author = {Hao, Ming and Bryant, Stephen H and Wang, Yanli},
year = {2019},
month = jul,
journal = {Briefings in Bioinformatics},
volume = {20},
number = {4},
pages = {1465--1474},
issn = {1477-4054},
doi = {10.1093/bib/bby010},
url = {https://doi.org/10.1093/bib/bby010},
urldate = {31 Oct. 2023},
abstract = {While novel technologies such as high-throughput screening have advanced together with significant investment by pharmaceutical companies during the past decades, the success rate for drug development has not yet been improved prompting researchers looking for new strategies of drug discovery. Drug repositioning is a potential approach to solve this dilemma. However, experimental identification and validation of potential drug targets encoded by the human genome is both costly and time-consuming. Therefore, effective computational approaches have been proposed to facilitate drug repositioning, which have proved to be successful in drug discovery. Doubtlessly, the availability of open-accessible data from basic chemical biology research and the success of human genome sequencing are crucial to develop effective in silico drug repositioning methods allowing the identification of potential targets for existing drugs. In this work, we review several chemogenomic data-driven computational algorithms with source codes publicly accessible for predicting drug--target interactions (DTIs). We organize these algorithms by model properties and model evolutionary relationships. We re-implemented five representative algorithms in R programming language, and compared these algorithms by means of mean percentile ranking, a new recall-based evaluation metric in the DTI prediction research field. We anticipate that this review will be objective and helpful to researchers who would like to further improve existing algorithms or need to choose appropriate algorithms to infer potential DTIs in the projects. The source codes for DTI predictions are available at: https://github.com/minghao2016/chemogenomicAlg4DTIpred.},
annotation = {25 citations (Crossref) [2023-10-31]},
file = {/home/pd/Zotero/storage/NLY33QRD/Hao et al. - 2019 - Open-source chemogenomic data-driven algorithms fo.pdf}
}

@book{hastie2001elements,
title = {The {{Elements}} of {{Statistical Learning}}},
author = {Hastie, Trevor and Friedman, Jerome and Tibshirani, Robert},
year = {2001},
series = {Springer {{Series}} in {{Statistics}}},
publisher = {Springer New York},
address = {New York},
doi = {10.1007/978-0-387-21606-5},
url = {http://link.springer.com/10.1007/978-0-387-21606-5},
urldate = {15 Mar. 2024},
isbn = {978-1-4899-0519-2 978-0-387-21606-5},
file = {/home/pd/Zotero/storage/7NEMCYVG/Hastie et al. - 2001 - The Elements of Statistical Learning.pdf}
}

@incollection{haynes2013benjamini,
title = {Benjamini--{{Hochberg Method}}},
booktitle = {Encyclopedia of {{Systems Biology}}},
author = {Haynes, Winston},
editor = {Dubitzky, Werner and Wolkenhauer, Olaf and Cho, Kwang-Hyun and Yokota, Hiroki},
year = {2013},
pages = {78--78},
publisher = {Springer},
address = {New York},
doi = {10.1007/978-1-4419-9863-7_1215},
url = {https://doi.org/10.1007/978-1-4419-9863-7_1215},
urldate = {17 Mar. 2024},
isbn = {978-1-4419-9863-7},
langid = {english}
}

@article{he2009learning,
title = {Learning from {{Imbalanced Data}}},
author = {He, Haibo and Garcia, Edwardo A.},
year = {2009},
month = sep,
journal = {IEEE Transactions on Knowledge and Data Engineering},
volume = {21},
number = {9},
pages = {1263--1284},
issn = {1558-2191},
doi = {10.1109/TKDE.2008.239},
url = {https://ieeexplore.ieee.org/abstract/document/5128907},
urldate = {17 Oct. 2023},
abstract = {With the continuous expansion of data availability in many large-scale, complex, and networked systems, such as surveillance, security, Internet, and finance, it becomes critical to advance the fundamental understanding of knowledge discovery and analysis from raw data to support decision-making processes. Although existing knowledge discovery and data engineering techniques have shown great success in many real-world applications, the problem of learning from imbalanced data (the imbalanced learning problem) is a relatively new challenge that has attracted growing attention from both academia and industry. The imbalanced learning problem is concerned with the performance of learning algorithms in the presence of underrepresented data and severe class distribution skews. Due to the inherent complex characteristics of imbalanced data sets, learning from such data requires new understandings, principles, algorithms, and tools to transform vast amounts of raw data efficiently into information and knowledge representation. In this paper, we provide a comprehensive review of the development of research in learning from imbalanced data. Our focus is to provide a critical review of the nature of the problem, the state-of-the-art technologies, and the current assessment metrics used to evaluate learning performance under the imbalanced learning scenario. Furthermore, in order to stimulate future research in this field, we also highlight the major opportunities and challenges, as well as potential important research directions for learning from imbalanced data.},
annotation = {4981 citations (Crossref) [2023-10-17]},
file = {/home/pd/Zotero/storage/QUTFAJP7/He and Garcia - 2009 - Learning from Imbalanced Data.pdf;/home/pd/Zotero/storage/DK2B5HKX/5128907.html}
}

@article{he2017simboost,
title = {{{SimBoost}}},
subtitle = {A Read-across Approach for Predicting Drug--Target Binding Affinities Using Gradient Boosting Machines},
author = {He, Tong and Heidemeyer, Marten and Ban, Fuqiang and Cherkasov, Artem and Ester, Martin},
year = {2017},
journal = {Journal of cheminformatics},
volume = {9},
number = {1},
pages = {1--14},
publisher = {BioMed Central},
keywords = {Applicability Domain,Drug-target interaction,Gradient boosting,Prediction interval,QSAR,Read-across},
file = {/home/pd/Zotero/storage/D7BPK2TH/He et al. - 2017 - SimBoost a read-across approach for predicting dr.pdf;/home/pd/Zotero/storage/QMSDCNGJ/s13321-017-0209-z.html}
}

@article{hsu2011mirtarbase,
title = {{{miRTarBase}}},
subtitle = {A Database Curates Experimentally Validated {{microRNA}}--Target Interactions},
author = {Hsu, Sheng-Da and Lin, Feng-Mao and Wu, Wei-Yun and Liang, Chao and Huang, Wei-Chih and Chan, Wen-Ling and Tsai, Wen-Ting and Chen, Goun-Zhou and Lee, Chia-Jung and Chiu, Chih-Min and others},
year = {2011},
journal = {Nucleic acids research},
volume = {39},
number = {suppl\_1},
pages = {D163--D169},
publisher = {Oxford University Press}
}

@article{hu2007genetic,
title = {Genetic Reconstruction of a Functional Transcriptional Regulatory Network},
author = {Hu, Zhanzhi and Killion, Patrick J and Iyer, Vishwanath R},
year = {2007},
journal = {Nature genetics},
volume = {39},
number = {5},
pages = {683--687},
publisher = {Nature Publishing Group US New York}
}

@inproceedings{hu2008collaborative,
title = {Collaborative {{Filtering}} for {{Implicit Feedback Datasets}}},
booktitle = {Proceedings [...]},
author = {Hu, Yifan and Koren, Yehuda and Volinsky, Chris},
year = {2008},
month = dec,
pages = {263--272},
publisher = {IEEE},
address = {Pisa},
doi = {10.1109/ICDM.2008.22},
url = {https://ieeexplore.ieee.org/abstract/document/4781121},
urldate = {31 Oct. 2023},
abstract = {A common task of recommender systems is to improve customer experience through personalized recommendations based on prior implicit feedback. These systems passively track different sorts of user behavior, such as purchase history, watching habits and browsing activity, in order to model user preferences. Unlike the much more extensively researched explicit feedback, we do not have any direct input from the users regarding their preferences. In particular, we lack substantial evidence on which products consumer dislike. In this work we identify unique properties of implicit feedback datasets. We propose treating the data as indication of positive and negative preference associated with vastly varying confidence levels. This leads to a factor model which is especially tailored for implicit feedback recommenders. We also suggest a scalable optimization procedure, which scales linearly with the data size. The algorithm is used successfully within a recommender system for television shows. It compares favorably with well tuned implementations of other known methods. In addition, we offer a novel way to give explanations to recommendations given by this factor model.},
organization = {INTERNATIONAL CONFERENCE ON DATA MINING, 8, 2008, Pisa},
file = {/home/pd/Zotero/storage/6WLQKXZW/Hu et al. - 2008 - Collaborative Filtering for Implicit Feedback Data.pdf;/home/pd/Zotero/storage/B2AXKDVP/4781121.html}
}

@article{huang2020deeppurpose,
title = {{{DeepPurpose}}},
subtitle = {A Deep Learning Library for Drug--Target Interaction Prediction},
author = {Huang, Kexin and Fu, Tianfan and Glass, Lucas M and Zitnik, Marinka and Xiao, Cao and Sun, Jimeng},
year = {2020},
journal = {Bioinformatics},
volume = {36},
number = {22-23},
pages = {5545--5547},
publisher = {Oxford University Press}
}

@article{huang2020moltrans,
title = {{{MolTrans}}},
subtitle = {{{Molecular Interaction Transformer}} for Drug--Target Interaction Prediction},
author = {Huang, Kexin and Xiao, Cao and Glass, Lucas M. and Sun, Jimeng},
editor = {Lu, Zhiyong},
year = {2020},
month = oct,
journal = {Bioinformatics},
volume = {37},
number = {6},
pages = {830--836},
publisher = {Oxford University Press (OUP)},
doi = {10.1093/bioinformatics/btaa880},
url = {https://doi.org/10.1093%2Fbioinformatics%2Fbtaa880},
annotation = {107 citations (Crossref) [2023-08-29]}
}

@article{huang2022mirtarbase,
title = {{{miRTarBase}} Update 2022},
subtitle = {An Informative Resource for Experimentally Validated {{miRNA}}--Target Interactions},
author = {Huang, Hsi-Yuan and Lin, Yang-Chi-Dung and Cui, Shidong and Huang, Yixian and Tang, Yun and Xu, Jiatong and Bao, Jiayang and Li, Yulin and Wen, Jia and Zuo, Huali and others},
year = {2022},
journal = {Nucleic acids research},
volume = {50},
number = {D1},
pages = {D222--D230},
publisher = {Oxford University Press}
}

@article{hughes2000functional,
title = {Functional Discovery via a Compendium of Expression Profiles},
author = {Hughes, Timothy R and Marton, Matthew J and Jones, Allan R and Roberts, Christopher J and Stoughton, Roland and Armour, Christopher D and Bennett, Holly A and Coffey, Ernest and Dai, Hongyue and He, Yudong D and others},
year = {2000},
journal = {Cell},
volume = {102},
number = {1},
pages = {109--126},
publisher = {Elsevier}
}

@article{hyafil1976constructing,
title = {Constructing Optimal Binary Decision Trees Is {{NP-complete}}},
author = {Hyafil, Laurent and Rivest, Ronald L.},
year = {1976},
month = may,
journal = {Information Processing Letters},
volume = {5},
number = {1},
pages = {15--17},
issn = {0020-0190},
doi = {10.1016/0020-0190(76)90095-8},
url = {https://www.sciencedirect.com/science/article/pii/0020019076900958},
urldate = {13 Mar. 2024},
keywords = {Binary decision trees,computational complexity,NP-complete},
annotation = {542 citations (Crossref) [2024-03-13]},
file = {/home/pd/Zotero/storage/NSC2QXKY/0020019076900958.html}
}

@inproceedings{jin2017multitask,
title = {Multitask {{Dyadic Prediction}} and {{Its Application}} in {{Prediction}} of {{Adverse Drug-Drug Interaction}}},
booktitle = {Proceedings [...]},
author = {Jin, Bo and Yang, Haoyu and Xiao, Cao and Zhang, Ping and Wei, Xiaopeng and Wang, Fei},
year = {2017},
month = feb,
publisher = {AAAI Press},
address = {Vancouver},
doi = {10.1609/aaai.v31i1.10718},
url = {https://ojs.aaai.org/index.php/AAAI/article/view/10718},
urldate = {17 Mar. 2024},
abstract = {Adverse drug-drug interactions (DDIs) remain a leading cause of morbidity and mortality around the world. Identifying potential DDIs during the drug design process is critical in guiding targeted clinical drug safety testing. Although detection of adverse DDIs is conducted during Phase IV clinical trials, there are still a large number of new DDIs founded by accidents after the drugs were put on market. With the arrival of big data era, more and more pharmaceutical research and development data are becoming available, which provides an invaluable resource for digging insights that can potentially be leveraged in early prediction of DDIs. Many computational approaches have been proposed in recent years for DDI prediction. However, most of them focused on binary prediction (with or without DDI), despite the fact that each DDI is associated with a different type. Predicting the actual DDI type will help us better understand the DDI mechanism and identify proper ways to prevent it. In this paper, we formulate the DDI type prediction problem as a multitask dyadic regression problem, where the prediction of each specific DDI type is treated as a task. Compared with conventional matrix completion approaches which can only impute the missing entries in the DDI matrix, our approach can directly regress those dyadic relationships (DDIs) and thus can be extend to new drugs more easily. We developed an effective proximal gradient method to solve the problem. Evaluation on real world datasets is presented to demonstrate the effectiveness of the proposed approach.},
copyright = {Copyright (c)},
langid = {english},
keywords = {biomedical application,multitask learning},
organization = {AAAI CONFERENCE ON ARTIFICIAL INTELIGENCE, 31, 2017, Vancouver},
file = {/home/pd/Zotero/storage/VGVZGBD7/Jin et al. - 2017 - Multitask Dyadic Prediction and Its Application in.pdf}
}

@article{johnson2014logistic,
title = {Logistic Matrix Factorization for Implicit Feedback Data},
author = {Johnson, Christopher C.},
year = {2014},
journal = {Advances in Neural Information Processing Systems},
volume = {27},
number = {78},
pages = {1--9},
publisher = {Montr{\'e}al, Canada},
url = {http://web.stanford.edu/~rezab/nips2014workshop/submits/logmat.pdf},
urldate = {25 Mar. 2024},
file = {/home/pd/Zotero/storage/DM3R94ZF/Johnson - 2014 - Logistic matrix factorization for implicit feedbac.pdf}
}

@article{keyvanpour2022dtiptc2a,
title = {{{DTIP-TC2A}}},
subtitle = {{{An}} Analytical Framework for Drug-Target Interactions Prediction Methods},
shorttitle = {{{DTIP-TC2A}}},
author = {Keyvanpour, Mohammad Reza and Haddadi, Faraneh and Mehrmolaei, Soheila},
year = {2022},
month = aug,
journal = {Computational Biology and Chemistry},
volume = {99},
pages = {107707},
issn = {1476-9271},
doi = {10.1016/j.compbiolchem.2022.107707},
url = {https://www.sciencedirect.com/science/article/pii/S1476927122000871},
urldate = {22 Nov. 2023},
abstract = {Identifying drug-target interactions through computational methods is raised an important and key step in the process of drug discovery and drug-oriented research during the last years. In addition to the advantages of existing computational methods, there are also challenges that affect methods' efficiency and provide obstacles in the direction of developing these computational methods. However, the literature suffers from lacking a comprehensive and comparative analysis concerning drug-target interactions prediction (DTIP) focusing on the analysis of technical and challenging aspects. It seems necessary to provide a comparative perspective and a different analysis on a macro level due to the importance of the DTIP problem. In this paper, we presented the quadruple framework of analytical, named DTIP-TC2A consists of four main components for DTIP. The first component, categorizing DTIP methods based on the technical aspect ahead and investigating the strengths and weaknesses of different DTIP methods. Second, classify DTIP challenges with a major focus on a well-organized and coherent investigation of challenges and presenting a macro view of the DTIP challenges by systematic identification of them. Third, recommending some general criteria to analyze DTIP methods in form of the proposed classifications. Suggesting a suitable set of qualitative criteria along with using quantitative criteria can lead to a more proper choice of DTIP methods. Fourth, performing a two-phase qualitative analysis and comparison between each class of DTIP approaches based on the proposed functional criteria and the identified challenges ahead in order to understand the superiority of each class of DTIP methods over the other class. We believed that the DTIP-TC2A framework can offer a proper context for efficient selection of DTIP methods, improving the efficiency of a DTIP system due to the nature of computational methods, upgrading DTIP methods by removing the barriers, and presenting new directions of research for further studies through systematic identification of DTIP challenges and purposeful evaluation of challenges and methods.},
keywords = {Biological network analysis,Challenge,Drug discovery,Drug-target interactions,DTIP,Qualitative evaluation},
annotation = {2 citations (Crossref) [2023-11-22]},
file = {/home/pd/Zotero/storage/MWG5X3UU/Keyvanpour et al. - 2022 - DTIP-TC2A An analytical framework for drug-target.pdf;/home/pd/Zotero/storage/KIQUBBF4/S1476927122000871.html}
}

@misc{kingma2017adam,
title = {Adam},
subtitle = {{{A Method}} for {{Stochastic Optimization}}},
shorttitle = {Adam},
author = {Kingma, Diederik P. and Ba, Jimmy},
year = {2017},
month = jan,
number = {arXiv:1412.6980},
eprint = {1412.6980},
primaryclass = {cs},
doi = {10.48550/arXiv.1412.6980},
url = {http://arxiv.org/abs/1412.6980},
urldate = {16 Mar. 2024},
abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
archiveprefix = {arxiv},
keywords = {Computer Science - Machine Learning},
file = {/home/pd/Zotero/storage/NIAFXVRI/Kingma and Ba - 2017 - Adam A Method for Stochastic Optimization.pdf;/home/pd/Zotero/storage/JBRXAD32/1412.html}
}

@incollection{kornbrot2014point,
title = {Point {{Biserial Correlation}}},
booktitle = {Wiley {{StatsRef}}: {{Statistics Reference Online}}},
author = {Kornbrot, Diana},
year = {2014},
publisher = {John Wiley \& Sons, Ltd},
address = {Hatfield},
doi = {10.1002/9781118445112.stat06227},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118445112.stat06227},
urldate = {03 Mar. 2024},
abstract = {The point biserial correlation is the value of Pearson's product moment correlation when one of the variables is dichotomous and the other variable is metric. Values range from +1, a perfect positive relation; through zero, no association at all; to -1, a perfect negative correlation. The square of this correlation, r p b 2 , is a measure of effect size in terms of the proportion of variability accounted for by the relation between the two variables.},
copyright = {Copyright {\copyright} 2005 John Wiley \& Sons, Ltd. All rights reserved.},
isbn = {978-1-118-44511-2},
langid = {english},
keywords = {association,bivariate,Pearson,t Test},
file = {/home/pd/Zotero/storage/VRCP3CY4/Kornbrot - 2014 - Point Biserial Correlation.pdf;/home/pd/Zotero/storage/XN5D9USL/9781118445112.html}
}

@article{krawczyk2016learning,
title = {Learning from Imbalanced Data},
subtitle = {Open Challenges and Future Directions},
shorttitle = {Learning from Imbalanced Data},
author = {Krawczyk, Bartosz},
year = {2016},
month = nov,
journal = {Progress in Artificial Intelligence},
volume = {5},
number = {4},
pages = {221--232},
issn = {2192-6360},
doi = {10.1007/s13748-016-0094-0},
url = {https://doi.org/10.1007/s13748-016-0094-0},
urldate = {17 Oct. 2023},
abstract = {Despite more than two decades of continuous development learning from imbalanced data is still a focus of intense research. Starting as a problem of skewed distributions of binary tasks, this topic evolved way beyond this conception. With the expansion of machine learning and data mining, combined with the arrival of big data era, we have gained a deeper insight into the nature of imbalanced learning, while at the same time facing new emerging challenges. Data-level and algorithm-level methods are constantly being improved and hybrid approaches gain increasing popularity. Recent trends focus on analyzing not only the disproportion between classes, but also other difficulties embedded in the nature of data. New real-life problems motivate researchers to focus on computationally efficient, adaptive and real-time methods. This paper aims at discussing open issues and challenges that need to be addressed to further develop the field of imbalanced learning. Seven vital areas of research in this topic are identified, covering the full spectrum of learning from imbalanced data: classification, regression, clustering, data streams, big data analytics and applications, e.g., in social media and computer vision. This paper provides a discussion and suggestions concerning lines of future research for each of them.},
langid = {english},
keywords = {Big data,Data streams,Imbalanced clustering,Imbalanced data,Imbalanced regression,Machine learning,Multi-class imbalance},
annotation = {1239 citations (Crossref) [2023-10-17]},
file = {/home/pd/Zotero/storage/NMPJSVEU/Krawczyk - 2016 - Learning from imbalanced data open challenges and.pdf}
}

@misc{landrum2023rdkit,
title = {Rdkit/Rdkit},
subtitle = {2023\_03\_2 ({{Q1}} 2023) {{Release}}},
author = {Landrum, Greg and Tosco, Paolo and Kelley, Brian and {Ric} and Cosgrove, David and {sriniker} and {gedeck} and Vianello, Riccardo and {NadineSchneider} and Kawashima, Eisuke and N, Dan and Jones, Gareth and Dalke, Andrew and Cole, Brian and Swain, Matt and Turk, Samo and {AlexanderSavelyev} and Vaucher, Alain and W{\'o}jcikowski, Maciej and Take, Ichiru and Probst, Daniel and Ujihara, Kazuya and Scalfani, Vincent F. and {godin}, guillaume and Lehtivarjo, Juuso and Pahl, Axel and Walker, Rachel and Berenger, Francois and {jasondbiggs} and {strets123}},
year = {2023},
month = jun,
doi = {10.5281/zenodo.8053810},
url = {https://doi.org/10.5281/zenodo.8053810},
howpublished = {Zenodo}
}

@article{levatic2017semisupervised,
title = {Semi-Supervised Classification Trees},
author = {Levati{\'c}, Jurica and Ceci, Michelangelo and Kocev, Dragi and D{\v z}eroski, Sa{\v s}o},
year = {2017},
journal = {Journal of Intelligent Information Systems},
volume = {49},
pages = {461--486},
publisher = {Springer},
doi = {10.1007/s10844-017-0457-4},
file = {/home/pd/Zotero/storage/7IYJFW5X/Levatić et al. - 2017 - Semi-supervised classification trees.pdf}
}

@article{li2019dnilmflda,
title = {{{DNILMF-LDA}}},
subtitle = {Prediction of {{lncRNA-disease}} Associations by Dual-Network Integrated Logistic Matrix Factorization and {{Bayesian}} Optimization},
author = {Li, Yan and Li, Junyi and Bian, Naizheng},
year = {2019},
journal = {Genes},
volume = {10},
number = {8},
pages = {608},
publisher = {MDPI}
}

@article{liu2005noncode,
title = {{{NONCODE}}},
subtitle = {An Integrated Knowledge Database of Non-Coding {{RNAs}}},
shorttitle = {{{NONCODE}}},
author = {Liu, Changning and Bai, Baoyan and Skogerb{\o}, Geir and Cai, Lun and Deng, Wei and Zhang, Yong and Bu, Dongbo and Zhao, Yi and Chen, Runsheng},
year = {2005},
journal = {Nucleic acids research},
volume = {33},
number = {suppl\_1},
pages = {D112--D115},
publisher = {Oxford University Press},
url = {https://academic.oup.com/nar/article-abstract/33/suppl_1/D112/2505275},
urldate = {15 Mar. 2024},
file = {/home/pd/Zotero/storage/YCN3ZR6V/2505275.html}
}

@inproceedings{liu2008isolation,
title = {Isolation {{Forest}}},
booktitle = {Proceedings [...]},
author = {Liu, Fei Tony and Ting, Kai Ming and Zhou, Zhi-Hua},
year = {2008},
month = dec,
pages = {413--422},
address = {Washington},
doi = {10.1109/ICDM.2008.17},
url = {https://ieeexplore.ieee.org/abstract/document/4781136},
urldate = {16 Mar. 2024},
abstract = {Most existing model-based approaches to anomaly detection construct a profile of normal instances, then identify instances that do not conform to the normal profile as anomalies. This paper proposes a fundamentally different model-based method that explicitly isolates anomalies instead of profiles normal points. To our best knowledge, the concept of isolation has not been explored in current literature. The use of isolation enables the proposed method, iForest, to exploit sub-sampling to an extent that is not feasible in existing methods, creating an algorithm which has a linear time complexity with a low constant and a low memory requirement. Our empirical evaluation shows that iForest performs favourably to ORCA, a near-linear time complexity distance-based method, LOF and random forests in terms of AUC and processing time, and especially in large data sets. iForest also works well in high dimensional problems which have a large number of irrelevant attributes, and in situations where training set does not contain any anomalies.},
keywords = {anomaly detection,Application software,Astronomy,binary trees,Constraint optimization,Credit cards,Data mining,Detectors,Information technology,isolation forest,Isolation technology,Laboratories,model based,novelty detection,outlier detection,Performance evaluation},
organization = {INTERNATIONAL CONFERENCE ON DATA MINING, 8, 2008, Washington},
file = {/home/pd/Zotero/storage/NRTVK7LM/Liu et al. - 2008 - Isolation Forest.pdf;/home/pd/Zotero/storage/4G6LDV5X/4781136.html}
}

@article{liu2016neighborhood,
title = {Neighborhood {{Regularized Logistic Matrix Factorization}} for {{Drug-Target Interaction Prediction}}},
author = {Liu, Yong and Wu, Min and Miao, Chunyan and Zhao, Peilin and Li, Xiao-Li},
editor = {Przytycka, Teresa M.},
year = {2016},
month = feb,
journal = {PLOS Computational Biology},
volume = {12},
number = {2},
pages = {e1004760},
publisher = {Public Library of Science (PLoS)},
doi = {10.1371/journal.pcbi.1004760},
url = {https://doi.org/10.1371%2Fjournal.pcbi.1004760},
keywords = {Drug discovery,Drug interactions,Drug therapy,Forecasting,G protein coupled receptors,Ion channels,Machine learning,Optimization},
annotation = {247 citations (Crossref) [2023-08-29]},
file = {/home/pd/Zotero/storage/7XT89MEH/Liu et al. - 2016 - Neighborhood Regularized Logistic Matrix Factoriza.pdf}
}

@incollection{liu2017computational,
title = {Computational {{Drug Discovery}} with {{Dyadic Positive-Unlabeled Learning}}},
booktitle = {Proceedings of the 2017 {{SIAM International Conference}} on {{Data Mining}} ({{SDM}})},
author = {Liu, Yashu and Qiu, Shuang and Zhang, Ping and Gong, Pinghua and Wang, Fei and Xue, Guoliang and Ye, Jieping},
year = {2017},
month = jun,
series = {Proceedings},
pages = {45--53},
publisher = {{Society for Industrial and Applied Mathematics}},
address = {Philadelphia},
doi = {10.1137/1.9781611974973.6},
url = {https://epubs.siam.org/doi/10.1137/1.9781611974973.6},
urldate = {30 Nov. 2023},
abstract = {Computational Drug Discovery, which uses computational techniques to facilitate and improve the drug discovery process, has aroused considerable interests in recent years. Drug Repositioning (DR) and Drug-Drug Interaction (DDI) prediction are two key problems in drug discovery and many computational techniques have been proposed for them in the last decade. Although these two problems have mostly been researched separately in the past, both DR and DDI can be formulated as the problem of detecting positive interactions between data entities (DR is between drug and disease, and DDI is between pairwise drugs). The challenge in both problems is that we can only observe a very small portion of positive interactions. In this paper, we propose a novel framework called Dyadic Positive-Unlabeled learning (DyPU) to solve the problem of detecting positive interactions. DyPU forces positive data pairs to rank higher than the average score of unlabeled data pairs. Moreover, we also derive the dual formulation of the proposed method with the rectifier scoring function and we show that the associated non-trivial proximal operator admits a closed form solution. Extensive experiments are conducted on real drug data sets and the results show that our method achieves superior performance comparing with the state-of-the-art.},
file = {/home/pd/Zotero/storage/F5JSNFG6/Liu et al. - 2017 - Computational Drug Discovery with Dyadic Positive-.pdf}
}

@article{liu2017lpinrlmf,
title = {{{LPI-NRLMF}}},
subtitle = {{{lncRNA-protein}} Interaction Prediction by Neighborhood Regularized Logistic Matrix Factorization},
author = {Liu, Hongsheng and Ren, Guofei and Hu, Huan and Zhang, Li and Ai, Haixin and Zhang, Wen and Zhao, Qi},
year = {2017},
journal = {Oncotarget},
volume = {8},
number = {61},
pages = {103975},
publisher = {Impact Journals, LLC}
}

@article{liu2020predicting,
title = {Predicting {{lncRNA}}--{{miRNA}} Interactions Based on Logistic Matrix Factorization with Neighborhood Regularized},
author = {Liu, Hongsheng and Ren, Guofei and Chen, Haoyu and Liu, Qi and Yang, Yingjuan and Zhao, Qi},
year = {2020},
journal = {Knowledge-Based Systems},
volume = {191},
pages = {105261},
publisher = {Elsevier}
}

@article{liu2022drugtarget,
title = {Drug-Target Interaction Prediction via an Ensemble of Weighted Nearest Neighbors with Interaction Recovery},
author = {Liu, Bin and Pliakos, Konstantinos and Vens, Celine and Tsoumakas, Grigorios},
year = {2022},
month = mar,
journal = {Applied Intelligence},
volume = {52},
number = {4},
pages = {3705--3727},
issn = {1573-7497},
doi = {10.1007/s10489-021-02495-z},
url = {https://doi.org/10.1007/s10489-021-02495-z},
urldate = {23 Mar. 2024},
abstract = {Predicting drug-target interactions (DTI) via reliable computational methods is an effective and efficient way to mitigate the enormous costs and time of the drug discovery process. Structure-based drug similarities and sequence-based target protein similarities are the commonly used information for DTI prediction. Among numerous computational methods, neighborhood-based chemogenomic approaches that leverage drug and target similarities to perform predictions directly are simple but promising ones. However, existing similarity-based methods need to be re-trained to predict interactions for any new drugs or targets and cannot directly perform predictions for both new drugs, new targets, and new drug-target pairs. Furthermore, a large amount of missing (undetected) interactions in current DTI datasets hinders most DTI prediction methods. To address these issues, we propose a new method denoted as Weighted k-Nearest Neighbor with Interaction Recovery (WkNNIR). Not only can WkNNIR estimate interactions of any new drugs and/or new targets without any need of re-training, but it can also recover missing interactions (false negatives). In addition, WkNNIR exploits local imbalance to promote the influence of more reliable similarities on the interaction recovery and prediction processes. We also propose a series of ensemble methods that employ diverse sampling strategies and could be coupled with WkNNIR as well as any other DTI prediction method to improve performance. Experimental results over five benchmark datasets demonstrate the effectiveness of our approaches in predicting drug-target interactions. Lastly, we confirm the practical prediction ability of proposed methods to discover reliable interactions that were not reported in the original benchmark datasets.},
langid = {english},
keywords = {Drug-target interactions,Ensemble learning,Interaction recovery,Local imbalance,Nearest neighbor},
annotation = {12 citations (Crossref) [2024-03-23]},
file = {/home/pd/Zotero/storage/XBWD3KNA/Liu et al. - 2022 - Drug-target interaction prediction via an ensemble.pdf}
}

@book{lodhi2010elements,
title = {Elements of {{Computational Systems Biology}}},
editor = {Lodhi, Huma M. and Muggleton, Stephen H.},
year = {2010},
month = jan,
edition = {First Edition},
publisher = {Wiley},
address = {Hoboken},
doi = {10.1002/9780470556757},
url = {https://onlinelibrary.wiley.com/doi/book/10.1002/9780470556757},
urldate = {29 Aug. 2023},
isbn = {978-0-470-18093-8 978-0-470-55675-7},
langid = {english},
file = {/home/pd/Zotero/storage/PSW9RM3V/[Wiley Series in Bioinformatics] Huma M. Lodhi, Stephen H. Muggleton - Elements of Computational Systems Biology (Wiley Series in Bioinformatics) (2010, Wiley) - libgen.li.pdf}
}

@article{loyola-gonzalez2020explainable,
title = {An {{Explainable Artificial Intelligence Model}} for {{Clustering Numerical Databases}}},
author = {{Loyola-Gonzalez}, Octavio and {Gutierrez-Rodriguez}, Andres Eduardo and {Medina-Perez}, Miguel Angel and Monroy, Raul and {Martinez-Trinidad}, Jose Francisco and {Carrasco-Ochoa}, Jesus Ariel and {Garcia-Borroto}, Milton},
year = {2020},
journal = {IEEE Access},
volume = {8},
pages = {52370--52384},
publisher = {{Institute of Electrical and Electronics Engineers (IEEE)}},
doi = {10.1109/access.2020.2980581},
url = {https://doi.org/10.1109%2Faccess.2020.2980581},
annotation = {24 citations (Crossref) [2023-08-29]},
file = {/home/pd/Zotero/storage/AWFMB9GF/Loyola-Gonzalez et al. - 2020 - An Explainable Artificial Intelligence Model for C.pdf}
}

@article{lu2011link,
title = {Link Prediction in Complex Networks},
subtitle = {{{A}} Survey},
shorttitle = {Link Prediction in Complex Networks},
author = {L{\"u}, Linyuan and Zhou, Tao},
year = {2011},
month = mar,
journal = {Physica A: Statistical Mechanics and its Applications},
volume = {390},
number = {6},
pages = {1150--1170},
issn = {0378-4371},
doi = {10.1016/j.physa.2010.11.027},
url = {https://www.sciencedirect.com/science/article/pii/S037843711000991X},
urldate = {17 Mar. 2024},
abstract = {Link prediction in complex networks has attracted increasing attention from both physical and computer science communities. The algorithms can be used to extract missing information, identify spurious interactions, evaluate network evolving mechanisms, and so on. This article summaries recent progress about link prediction algorithms, emphasizing on the contributions from physical perspectives and approaches, such as the random-walk-based methods and the maximum likelihood methods. We also introduce three typical applications: reconstruction of networks, evaluation of network evolving mechanism and classification of partially labeled networks. Finally, we introduce some applications and outline future challenges of link prediction algorithms.},
keywords = {Complex networks,Link prediction,Maximum likelihood methods,Node similarity,Probabilistic models},
annotation = {1878 citations (Crossref) [2024-03-17]},
file = {/home/pd/Zotero/storage/PWSZLNB8/Lü and Zhou - 2011 - Link prediction in complex networks A survey.pdf;/home/pd/Zotero/storage/BFCRVN2E/S037843711000991X.html}
}

@article{lu2012recommender,
title = {Recommender Systems},
author = {L{\"u}, Linyuan and Medo, Mat{\'u}{\v s} and Yeung, Chi Ho and Zhang, Yi-Cheng and Zhang, Zi-Ke and Zhou, Tao},
year = {2012},
month = oct,
journal = {Physics Reports},
series = {Recommender {{Systems}}},
volume = {519},
number = {1},
pages = {1--49},
issn = {0370-1573},
doi = {10.1016/j.physrep.2012.02.006},
url = {https://www.sciencedirect.com/science/article/pii/S0370157312000828},
urldate = {15 Mar. 2024},
abstract = {The ongoing rapid expansion of the Internet greatly increases the necessity of effective recommender systems for filtering the abundant information. Extensive research for recommender systems is conducted by a broad range of communities including social and computer scientists, physicists, and interdisciplinary researchers. Despite substantial theoretical and practical achievements, unification and comparison of different approaches are lacking, which impedes further advances. In this article, we review recent developments in recommender systems and discuss the major challenges. We compare and evaluate available algorithms and examine their roles in the future developments. In addition to algorithms, physical aspects are described to illustrate macroscopic behavior of recommender systems. Potential impacts and future directions are discussed. We emphasize that recommendation has great scientific depth and combines diverse research fields which makes it interesting for physicists as well as interdisciplinary researchers.},
keywords = {Information filtering,Networks,Recommender systems},
annotation = {766 citations (Crossref) [2024-03-15]},
file = {/home/pd/Zotero/storage/RRG9JB2C/Lü et al. - 2012 - Recommender systems.pdf;/home/pd/Zotero/storage/KUTF6XJ6/S0370157312000828.html}
}

@misc{lundberg2019explainable,
title = {Explainable {{AI}} for {{Trees}}},
subtitle = {{{From Local Explanations}} to {{Global Understanding}}},
shorttitle = {Explainable {{AI}} for {{Trees}}},
author = {Lundberg, Scott M. and Erion, Gabriel and Chen, Hugh and DeGrave, Alex and Prutkin, Jordan M. and Nair, Bala and Katz, Ronit and Himmelfarb, Jonathan and Bansal, Nisha and Lee, Su-In},
year = {2019},
month = may,
number = {arXiv:1905.04610},
eprint = {1905.04610},
primaryclass = {cs, stat},
doi = {10.48550/arXiv.1905.04610},
url = {http://arxiv.org/abs/1905.04610},
urldate = {15 Mar. 2024},
abstract = {Tree-based machine learning models such as random forests, decision trees, and gradient boosted trees are the most popular non-linear predictive models used in practice today, yet comparatively little attention has been paid to explaining their predictions. Here we significantly improve the interpretability of tree-based models through three main contributions: 1) The first polynomial time algorithm to compute optimal explanations based on game theory. 2) A new type of explanation that directly measures local feature interaction effects. 3) A new set of tools for understanding global model structure based on combining many local explanations of each prediction. We apply these tools to three medical machine learning problems and show how combining many high-quality local explanations allows us to represent global structure while retaining local faithfulness to the original model. These tools enable us to i) identify high magnitude but low frequency non-linear mortality risk factors in the general US population, ii) highlight distinct population sub-groups with shared risk characteristics, iii) identify non-linear interaction effects among risk factors for chronic kidney disease, and iv) monitor a machine learning model deployed in a hospital by identifying which features are degrading the model's performance over time. Given the popularity of tree-based machine learning models, these improvements to their interpretability have implications across a broad set of domains.},
archiveprefix = {arxiv},
keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
file = {/home/pd/Zotero/storage/MCSLU27G/Lundberg et al. - 2019 - Explainable AI for Trees From Local Explanations .pdf;/home/pd/Zotero/storage/N7ET69ZS/1905.html}
}

@article{macisaac2006improved,
title = {An Improved Map of Conserved Regulatory Sites for {{Saccharomyces}} Cerevisiae},
author = {MacIsaac, Kenzie D and Wang, Ting and Gordon, D Benjamin and Gifford, David K and Stormo, Gary D and Fraenkel, Ernest},
year = {2006},
journal = {BMC bioinformatics},
volume = {7},
number = {1},
pages = {1--14},
publisher = {BioMed Central}
}

@article{marco2017atlantic,
title = {Atlantic Frugivory},
subtitle = {A Plant{\^a} Frugivore Interaction Data Set for the {{Atlantic Forest}}},
author = {Marco, A and Tatiane, C and Wesley, R and Fernanda, R and others},
year = {2017},
journal = {Ecology},
publisher = {John Wiley \& Sons, Ltd}
}

@article{mei2013drug,
title = {Drug--Target Interaction Prediction by Learning from Local Information and Neighbors},
author = {Mei, Jian-Ping and Kwoh, Chee-Keong and Yang, Peng and Li, Xiao-Li and Zheng, Jie},
year = {2013},
journal = {Bioinformatics},
volume = {29},
number = {2},
pages = {238--245},
publisher = {Oxford University Press},
doi = {10.1093/bioinformatics/bts670},
file = {/home/pd/Zotero/storage/BGH2XR6D/Mei et al. - 2013 - Drug–target interaction prediction by learning fro.pdf}
}

@inproceedings{menon2010loglinear,
title = {A {{Log-Linear Model}} with {{Latent Features}} for {{Dyadic Prediction}}},
booktitle = {Proceedings [...]},
author = {Menon, Aditya Krishna and Elkan, Charles},
year = {2010},
month = dec,
pages = {364--373},
publisher = {IEEE Press},
address = {Washington},
doi = {10.1109/ICDM.2010.148},
url = {https://ieeexplore.ieee.org/abstract/document/5693990?casa_token=5XEvIOHU1OMAAAAA:Bymab0jmtjfbBmayXVALNP8CnIeLGi9Qh3CG1SPewKStCzpACWf91Q1zKh8I_UUrUPYYncLOEOs},
urldate = {17 Mar. 2024},
abstract = {In dyadic prediction, labels must be predicted for pairs (dyads) whose members possess unique identifiers and, sometimes, additional features called side-information. Special cases of this problem include collaborative filtering and link prediction. We present a new log-linear model for dyadic prediction that is the first to satisfy several important desiderata: (i) labels may be ordinal or nominal, (ii) side-information can be easily exploited if present, (iii) with or without side-information, latent features are inferred for dyad members, (iv) the model is resistant to sample-selection bias, (v) it can learn well-calibrated probabilities, and (vi) it can scale to large datasets. To our knowledge, no existing method satisfies all the above criteria. In particular, many methods assume that the labels are binary or numerical, and cannot use side-information. Experimental results show that the new method is competitive with previous specialized methods for collaborative filtering and link prediction. Other experimental results demonstrate that the new method succeeds for dyadic prediction tasks where previous methods cannot be used. In particular, the new method predicts nominal labels accurately, and by using side-information it solves the cold-start problem in collaborative filtering.},
keywords = {Approximation methods,Collaboration,collaborative filtering,Data models,Dyadic prediction,link prediction,log-linear model,Mathematical model,Numerical models,Predictive models,Training},
organization = {INTERNATIONAL CONFERENCE ON DATA MINING, 10, 2010, Washington},
file = {/home/pd/Zotero/storage/9NNBMJX8/Menon and Elkan - 2010 - A Log-Linear Model with Latent Features for Dyadic.pdf;/home/pd/Zotero/storage/6ASZ9E2K/5693990.html}
}

@book{murphy2012machine,
title = {Machine Learning},
subtitle = {A Probabilistic Perspective},
shorttitle = {Machine Learning},
author = {Murphy, Kevin P.},
year = {2012},
series = {Adaptive Computation and Machine Learning Series},
publisher = {MIT Press},
address = {Cambridge},
isbn = {978-0-262-01802-9},
lccn = {Q325.5 .M87 2012},
keywords = {Machine learning,Probabilities},
file = {/home/pd/Zotero/storage/VW9YJI3Q/Murphy - 2012 - Machine learning a probabilistic perspective.pdf}
}

@article{natekin2013gradient,
title = {Gradient Boosting Machines, a Tutorial},
author = {Natekin, Alexey and Knoll, Alois},
year = {2013},
month = dec,
journal = {Frontiers in Neurorobotics},
volume = {7},
publisher = {Frontiers},
issn = {1662-5218},
doi = {10.3389/fnbot.2013.00021},
url = {https://www.frontiersin.org/articles/10.3389/fnbot.2013.00021},
urldate = {16 Mar. 2024},
abstract = {Gradient boosting machines are a family of powerful machine-learning techniques that have shown considerable success in a wide range of practical applications. They are highly customizable to the particular needs of the application, like being learned with respect to different loss functions. This article gives a tutorial introduction into the methodology of gradient boosting methods. A theoretical information is complemented with many descriptive examples and illustrations which cover all the stages of the gradient boosting model design. Considerations on handling the model complexity are discussed. A set of practical examples of gradient boosting applications are presented and comprehensively analyzed.},
langid = {english},
keywords = {boosting,Classification,gradient boosting,machine learning,regression,robotic control,text classification},
annotation = {1412 citations (Crossref) [2024-03-16]},
file = {/home/pd/Zotero/storage/WGVGS3D8/Natekin and Knoll - 2013 - Gradient boosting machines, a tutorial.pdf}
}

@article{ozenne2015precision,
title = {The Precision--Recall Curve Overcame the Optimism of the Receiver Operating Characteristic Curve in Rare Diseases},
author = {Ozenne, Brice and Subtil, Fabien and {Maucort-Boulch}, Delphine},
year = {2015},
month = aug,
journal = {Journal of Clinical Epidemiology},
volume = {68},
number = {8},
pages = {855--859},
issn = {0895-4356},
doi = {10.1016/j.jclinepi.2015.02.010},
url = {https://www.sciencedirect.com/science/article/pii/S0895435615001067},
urldate = {31 Oct. 2023},
abstract = {Objectives Compare the area under the receiver operating characteristic curve (AUC) vs. the area under the precision--recall curve (AUPRC) in summarizing the performance of a diagnostic biomarker according to the disease prevalence. Study Design and Setting A simulation study was performed considering different sizes of diseased and nondiseased groups. Values of a biomarker were sampled with various variances and differences in mean values between the two groups. The AUCs and the AUPRCs were examined regarding their agreement and vs. the positive predictive value (PPV) and the negative predictive value (NPV) of the biomarker. Results With a disease prevalence of 50\%, the AUC and the AUPRC showed high correlations with the PPV and the NPV ({$\rho~>~$}0.95). With a prevalence of 1\%, small PPV and AUPRC values ({$<$}0.2) but high AUC values ({$>$}0.9) were found. The AUPRC reflected better than the AUC the discriminant ability of the biomarker; it had a higher correlation with the PPV ({$\rho~$}=~0.995 vs. 0.724; P~{$<~$}0.001). Conclusion In uncommon and rare diseases, the AUPRC should be preferred to the AUC because it summarizes better the performance of a biomarker.},
keywords = {Area under the curve,Binary biomarker,Performance assessment,Precision-Recall curve,Rare events,Receiver operating curve},
annotation = {183 citations (Crossref) [2023-10-30]},
file = {/home/pd/Zotero/storage/8DLVAUSM/Ozenne et al. - 2015 - The precision–recall curve overcame the optimism o.pdf}
}

@article{ozturk2018deepdta,
title = {{{DeepDTA}}},
subtitle = {Deep Drug--Target Binding Affinity Prediction},
author = {{\"O}zt{\"u}rk, Hakime and {\"O}zg{\"u}r, Arzucan and Ozkirimli, Elif},
year = {2018},
journal = {Bioinformatics},
volume = {34},
number = {17},
pages = {i821--i829},
publisher = {Oxford University Press},
keywords = {deep learning,drug-target,predictor}
}

@inproceedings{pahikkala2014twostep,
title = {A {{Two-Step Learning Approach}} for {{Solving Full}} and {{Almost Full Cold Start Problems}} in {{Dyadic Prediction}}},
booktitle = {Machine {{Learning}} and {{Knowledge Discovery}} in {{Databases}}},
author = {Pahikkala, Tapio and Stock, Michiel and Airola, Antti and Aittokallio, Tero and De Baets, Bernard and Waegeman, Willem},
editor = {Calders, Toon and Esposito, Floriana and H{\"u}llermeier, Eyke and Meo, Rosa},
year = {2014},
pages = {517--532},
publisher = {Springer},
address = {Berlin},
doi = {10.1007/978-3-662-44851-9_33},
abstract = {Dyadic prediction methods operate on pairs of objects (dyads), aiming to infer labels for out-of-sample dyads. We consider the full and almost full cold start problem in dyadic prediction, a setting that occurs when both objects in an out-of-sample dyad have not been observed during training, or if one of them has been observed, but very few times. A popular approach for addressing this problem is to train a model that makes predictions based on a pairwise feature representation of the dyads, or, in case of kernel methods, based on a tensor product pairwise kernel. As an alternative to such a kernel approach, we introduce a novel two-step learning algorithm that borrows ideas from the fields of pairwise learning and spectral filtering. We show theoretically that the two-step method is very closely related to the tensor product kernel approach, and experimentally that it yields a slightly better predictive performance. Moreover, unlike existing tensor product kernel methods, the two-step method allows closed-form solutions for training and parameter selection via cross-validation estimates both in the full and almost full cold start settings, making the approach much more efficient and straightforward to implement.},
isbn = {978-3-662-44851-9},
langid = {english},
keywords = {Dyadic prediction,kernel methods,kernel ridge regression,pairwise learning,transfer learning},
organization = {MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES, 2014, Berlin},
file = {/home/pd/Zotero/storage/BCZAF3PQ/Pahikkala et al. - 2014 - A Two-Step Learning Approach for Solving Full and .pdf}
}

@article{pahikkala2015more,
title = {Toward More Realistic Drug-Target Interaction Predictions},
author = {Pahikkala, Tapio and Airola, Antti and Pietil{\"a}, Sami and Shakyawar, Sushil and Szwajda, Agnieszka and Tang, Jing and Aittokallio, Tero},
year = {2015},
journal = {Briefings in Bioinformatics},
volume = {16},
number = {2},
pages = {325--337},
doi = {10.1093/bib/bbu010},
url = {http://dx.doi.org/10.1093/bib/bbu010},
annotation = {261 citations (Crossref) [2023-08-29]},
file = {/home/pd/Zotero/storage/ZUCZUUWS/Pahikkala et al. - 2015 - Toward more realistic drug-target interaction pred.pdf}
}

@article{pedregosa2011scikitlearn,
title = {Scikit-Learn},
subtitle = {{{Machine Learning}} in {{Python}}},
shorttitle = {Scikit-Learn},
author = {Pedregosa, Fabian and Varoquaux, Ga{\"e}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, {\'E}douard},
year = {2011},
journal = {Journal of Machine Learning Research},
volume = {12},
number = {85},
pages = {2825--2830},
issn = {1533-7928},
url = {http://jmlr.org/papers/v12/pedregosa11a.html},
urldate = {16 Mar. 2024},
abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.},
file = {/home/pd/Zotero/storage/PEJBGGX5/Pedregosa et al. - 2011 - Scikit-learn Machine Learning in Python.pdf}
}

@article{pliakos2018global,
title = {Global Multi-Output Decision Trees for Interaction Prediction},
author = {Pliakos, Konstantinos and Geurts, Pierre and Vens, Celine},
year = {2018},
journal = {Machine Learning},
volume = {107},
pages = {1257--1281},
publisher = {Springer},
doi = {10.1007/s10994-018-5700-x},
file = {/home/pd/Zotero/storage/X66MLN8W/Pliakos et al. - 2018 - Global multi-output decision trees for interaction.pdf}
}

@article{pliakos2019network,
title = {Network Inference with Ensembles of Bi-Clustering Trees},
author = {Pliakos, Konstantinos and Vens, Celine},
year = {2019},
journal = {BMC bioinformatics},
volume = {20},
pages = {1--12},
publisher = {Springer},
doi = {10.1186/s12859-019-3104-y},
file = {/home/pd/Zotero/storage/J2JXKQCE/Pliakos and Vens - 2019 - Network inference with ensembles of bi-clustering .pdf}
}

@article{pliakos2020drugtarget,
title = {Drug-Target Interaction Prediction with Tree-Ensemble Learning and Output Space Reconstruction},
author = {Pliakos, Konstantinos and Vens, Celine},
year = {2020},
journal = {BMC bioinformatics},
volume = {21},
pages = {1--11},
publisher = {Springer}
}

@article{polikar2006ensemble,
title = {Ensemble Based Systems in Decision Making},
author = {Polikar, R.},
year = {2006},
journal = {IEEE Circuits and Systems Magazine},
volume = {6},
number = {3},
pages = {21--45},
issn = {1531-636X},
doi = {10.1109/MCAS.2006.1688199},
url = {http://ieeexplore.ieee.org/document/1688199/},
urldate = {23 Sep. 2023},
annotation = {1864 citations (Crossref) [2023-09-23]}
}

@misc{powers2020evaluation,
title = {Evaluation},
subtitle = {From Precision, Recall and {{F-measure}} to {{ROC}}, Informedness, Markedness and Correlation},
shorttitle = {Evaluation},
author = {Powers, David M. W.},
year = {2020},
month = oct,
number = {arXiv:2010.16061},
eprint = {2010.16061},
primaryclass = {cs, stat},
url = {http://arxiv.org/abs/2010.16061},
urldate = {15 Mar. 2024},
abstract = {Commonly used evaluation measures including Recall, Precision, F-Measure and Rand Accuracy are biased and should not be used without clear understanding of the biases, and corresponding identification of chance or base case levels of the statistic. Using these measures a system that performs worse in the objective sense of Informedness, can appear to perform better under any of these commonly used measures. We discuss several concepts and measures that reflect the probability that prediction is informed versus chance. Informedness and introduce Markedness as a dual measure for the probability that prediction is marked versus chance. Finally we demonstrate elegant connections between the concepts of Informedness, Markedness, Correlation and Significance as well as their intuitive relationships with Recall and Precision, and outline the extension from the dichotomous case to the general multi-class case.},
archiveprefix = {arxiv},
keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Statistics - Methodology},
file = {/home/pd/Zotero/storage/998CX29F/Powers - 2020 - Evaluation from precision, recall and F-measure t.pdf;/home/pd/Zotero/storage/5TT3C623/2010.html}
}

@article{quinlan1986induction,
title = {Induction of Decision Trees},
author = {Quinlan, J. R.},
year = {1986},
month = mar,
journal = {Machine Learning},
volume = {1},
number = {1},
pages = {81--106},
issn = {1573-0565},
doi = {10.1007/BF00116251},
url = {https://doi.org/10.1007/BF00116251},
urldate = {15 Mar. 2024},
abstract = {The technology for building knowledge-based systems by inductive inference from examples has been demonstrated successfully in several practical applications. This paper summarizes an approach to synthesizing decision trees that has been used in a variety of systems, and it describes one such system, ID3, in detail. Results from recent studies show ways in which the methodology can be modified to deal with information that is noisy and/or incomplete. A reported shortcoming of the basic algorithm is discussed and two means of overcoming it are compared. The paper concludes with illustrations of current research directions.},
langid = {english},
keywords = {classification,decision trees,expert systems,induction,information theory,knowledge acquisition},
annotation = {8796 citations (Crossref) [2024-03-15]},
file = {/home/pd/Zotero/storage/SCC8M9SC/Quinlan - 1986 - Induction of decision trees.pdf}
}

@article{quinlan1986inductiona,
title = {Induction of Decision Trees},
author = {Quinlan, J. R.},
year = {1986},
month = mar,
journal = {Machine Learning},
volume = {1},
number = {1},
pages = {81--106},
issn = {0885-6125, 1573-0565},
doi = {10.1007/BF00116251},
url = {http://link.springer.com/10.1007/BF00116251},
urldate = {15 Mar. 2024},
langid = {english},
annotation = {8796 citations (Crossref) [2024-03-15]},
file = {/home/pd/Zotero/storage/796KZYJC/Quinlan - 1986 - Induction of decision trees.pdf}
}

@book{quinlan2014c4,
title = {C4. 5},
subtitle = {Programs for Machine Learning},
shorttitle = {C4. 5},
author = {Quinlan, J. Ross},
year = {2014},
publisher = {Elsevier},
url = {https://books.google.com/books?hl=pt-BR&lr=&id=b3ujBQAAQBAJ&oi=fnd&pg=PP1&dq=quinlan+programs&ots=sS2mWLHrD2&sig=N3A5U153LT9H8Z9okfYYd-y9L7c},
urldate = {15 Mar. 2024}
}

@article{rafailidis2016modeling,
title = {Modeling {{Users Preference Dynamics}} and {{Side Information}} in {{Recommender Systems}}},
author = {Rafailidis, Dimitrios and Nanopoulos, Alexandros},
year = {2016},
month = jun,
journal = {IEEE Transactions on Systems, Man, and Cybernetics: Systems},
volume = {46},
number = {6},
pages = {782--792},
issn = {2168-2232},
doi = {10.1109/TSMC.2015.2460691},
url = {https://ieeexplore.ieee.org/abstract/document/7194815},
urldate = {15 Mar. 2024},
abstract = {In recommender systems user preferences can be fairly dynamic, as users tend to exploit a wide range of items and modify their tastes accordingly over time. In this paper, we model user-item interactions over time using a tensor that has time as a dimension (mode). To account for the fact that user preferences change individually, we propose a new measure of user-preference dynamics (UPD) that captures the rate with which the current preferences of each user have been shifted. UPD shows the variability in how users interact with items in recommender systems. We generate recommendations based on a tensor factorization technique, where the importance of past user preferences are weighted according to their UPD values, that is, higher UPD values downweigh more past user preferences. Additionally, we exploit users' side data, such as demographics, which improve the accuracy of recommendations based on a coupled tensor-matrix factorization scheme. Our empirical evaluation uses two real benchmark datasets from the social media platforms Last.fm and MovieLens, containing users' history records pertaining to listening to songs and viewing movies, respectively. We demonstrate that in both datasets, there are users with a varying level of dynamics, expressed by the UPD metric. Our experimental results show that the proposed method outperforms several baselines, by taking into account both dynamics and side data of users.},
keywords = {Approximation methods,Collaboration,Coupled tensor factorization (CTF),Motion pictures,Music,Optimization,recommender systems,Recommender systems,Tensile stress,users' dynamics},
annotation = {82 citations (Crossref) [2024-03-15]},
file = {/home/pd/Zotero/storage/SIJGHELP/Rafailidis and Nanopoulos - 2016 - Modeling Users Preference Dynamics and Side Inform.pdf;/home/pd/Zotero/storage/DNILAR59/7194815.html}
}

@article{rodriguez2006rotation,
title = {Rotation Forest},
subtitle = {{{A}} New Classifier Ensemble Method},
shorttitle = {Rotation Forest},
author = {Rodriguez, Juan Jos{\'e} and Kuncheva, Ludmila I. and Alonso, Carlos J.},
year = {2006},
journal = {IEEE transactions on pattern analysis and machine intelligence},
volume = {28},
number = {10},
pages = {1619--1630},
publisher = {IEEE},
doi = {10.1109/TPAMI.2006.211},
url = {https://ieeexplore.ieee.org/abstract/document/1677518/},
urldate = {16 Mar. 2024}
}

@article{rogers2005using,
title = {Using Extended-Connectivity Fingerprints with {{Laplacian-modified Bayesian}} Analysis in High-Throughput Screening Follow-Up},
author = {Rogers, David and Brown, Robert D and Hahn, Mathew},
year = {2005},
journal = {Journal of biomolecular screening},
volume = {10},
number = {7},
pages = {682--686},
publisher = {Sage Publications Sage CA: Thousand Oaks, CA}
}

@article{ru2022nerltrdta,
title = {{{NerLTR-DTA}}},
subtitle = {Drug--Target Binding Affinity Prediction Based on Neighbor Relationship and Learning to Rank},
shorttitle = {{{NerLTR-DTA}}},
author = {Ru, Xiaoqing and Ye, Xiucai and Sakurai, Tetsuya and Zou, Quan},
year = {2022},
month = mar,
journal = {Bioinformatics},
volume = {38},
number = {7},
pages = {1964--1971},
issn = {1367-4803},
doi = {10.1093/bioinformatics/btac048},
url = {https://doi.org/10.1093/bioinformatics/btac048},
urldate = {22 Nov. 2023},
abstract = {Drug--target interaction prediction plays an important role in new drug discovery and drug repurposing. Binding affinity indicates the strength of drug--target interactions. Predicting drug--target binding affinity is expected to provide promising candidates for biologists, which can effectively reduce the workload of wet laboratory experiments and speed up the entire process of drug research. Given that, numerous new proteins are sequenced and compounds are synthesized, several improved computational methods have been proposed for such predictions, but there are still some challenges. (i) Many methods only discuss and implement one application scenario, they focus on drug repurposing and ignore the discovery of new drugs and targets. (ii) Many methods do not consider the priority order of proteins (or drugs) related to each target drug (or protein). Therefore, it is necessary to develop a comprehensive method that can be used in multiple scenarios and focuses on candidate order.In this study, we propose a method called NerLTR-DTA that uses the neighbor relationship of similarity and sharing to extract features, and applies a ranking framework with regression attributes to predict affinity values and priority order of query drug (or query target) and its related proteins (or compounds). It is worth noting that using the characteristics of learning to rank to set different queries can smartly realize the multi-scenario application of the method, including the discovery of new drugs and new targets. Experimental results on two commonly used datasets show that NerLTR-DTA outperforms some state-of-the-art competing methods. NerLTR-DTA achieves excellent performance in all application scenarios mentioned in this study, and the rm(test)2 values guarantee such excellent performance is not obtained by chance. Moreover, it can be concluded that NerLTR-DTA can provide accurate ranking lists for the relevant results of most queries through the statistics of the association relationship of each query drug (or query protein). In general, NerLTR-DTA is a powerful tool for predicting drug--target associations and can contribute to new drug discovery and drug repurposing.The proposed method is implemented in Python and Java. Source codes and datasets are available at https://github.com/RUXIAOQING964914140/NerLTR-DTA.},
annotation = {23 citations (Crossref) [2023-11-22]},
file = {/home/pd/Zotero/storage/4ZIU7WYQ/Ru et al. - 2022 - NerLTR-DTA drug–target binding affinity predictio.pdf;/home/pd/Zotero/storage/48E4ZXZX/6522110.html}
}

@article{sagi2018ensemble,
title = {Ensemble Learning},
subtitle = {{{A}} Survey},
shorttitle = {Ensemble Learning},
author = {Sagi, Omer and Rokach, Lior},
year = {2018},
month = jul,
journal = {WIREs Data Mining and Knowledge Discovery},
volume = {8},
number = {4},
pages = {e1249},
issn = {1942-4787, 1942-4795},
doi = {10.1002/widm.1249},
url = {https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1249},
urldate = {23 Sep. 2023},
abstract = {Ensemble methods are considered the state-of-the art solution for many machine learning challenges. Such methods improve the predictive performance of a single model by training multiple models and combining their predictions. This paper introduce the concept of ensemble learning, reviews traditional, novel and state-of-the-art ensemble methods and discusses current challenges and trends in the field. This article is categorized under: Algorithmic Development {$>$} Ensemble Methods Technologies {$>$} Machine Learning Technologies {$>$} Classification},
langid = {english},
annotation = {886 citations (Crossref) [2023-09-23]}
}

@article{saito2015precisionrecall,
title = {The {{Precision-Recall Plot Is More Informative}} than the {{ROC Plot When Evaluating Binary Classifiers}} on {{Imbalanced Datasets}}},
author = {Saito, Takaya and Rehmsmeier, Marc},
year = {2015},
month = mar,
journal = {PLOS ONE},
volume = {10},
number = {3},
pages = {e0118432},
publisher = {Public Library of Science},
issn = {1932-6203},
doi = {10.1371/journal.pone.0118432},
url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0118432},
urldate = {18 Oct. 2023},
abstract = {Binary classifiers are routinely evaluated with performance measures such as sensitivity and specificity, and performance is frequently illustrated with Receiver Operating Characteristics (ROC) plots. Alternative measures such as positive predictive value (PPV) and the associated Precision/Recall (PRC) plots are used less frequently. Many bioinformatics studies develop and evaluate classifiers that are to be applied to strongly imbalanced datasets in which the number of negatives outweighs the number of positives significantly. While ROC plots are visually appealing and provide an overview of a classifier's performance across a wide range of specificities, one can ask whether ROC plots could be misleading when applied in imbalanced classification scenarios. We show here that the visual interpretability of ROC plots in the context of imbalanced datasets can be deceptive with respect to conclusions about the reliability of classification performance, owing to an intuitive but wrong interpretation of specificity. PRC plots, on the other hand, can provide the viewer with an accurate prediction of future classification performance due to the fact that they evaluate the fraction of true positives among positive predictions. Our findings have potential implications for the interpretation of a large number of studies that use ROC plots on imbalanced datasets.},
langid = {english},
keywords = {Bioinformatics,Caenorhabditis elegans,Exponential functions,Genome-wide association studies,Interpolation,Measurement,MicroRNAs,Support vector machines},
annotation = {2037 citations (Crossref) [2023-10-18]},
file = {/home/pd/Zotero/storage/WH5S8GHK/Saito and Rehmsmeier - 2015 - The Precision-Recall Plot Is More Informative than.pdf}
}

@inproceedings{santos2021predictive,
title = {Predictive {{Bi-clustering Trees}} for {{Hierarchical Multi-label Classification}}},
booktitle = {Machine {{Learning}} and {{Knowledge Discovery}} in {{Databases}}},
author = {Santos, Bruna Z. and Nakano, Felipe K. and Cerri, Ricardo and Vens, Celine},
editor = {Hutter, Frank and Kersting, Kristian and Lijffijt, Jefrey and Valera, Isabel},
year = {2021},
pages = {701--718},
publisher = {Springer International Publishing},
address = {Cham},
doi = {10.1007/978-3-030-67664-3_42},
abstract = {In the recent literature on multi-label classification, a lot of attention is given to methods that exploit label dependencies. Most of these methods assume that the dependencies are static over the entire instance space. In contrast, here we present an approach that dynamically adapts the label partitions in a multi-label decision tree learning context. In particular, we adapt the recently introduced predictive bi-clustering tree (PBCT) method towards multi-label classification tasks. This way, tree nodes can split the instance-label matrix both in a horizontal and a vertical way. We focus on hierarchical multi-label classification (HMC) tasks, and map the label hierarchy to a feature set over the label space. This feature set is exploited to infer vertical splits, which are regulated by a lookahead strategy in the tree building procedure. We evaluate our proposed method using benchmark datasets. Experiments demonstrate that our proposal (PBCT-HMC) obtained better or competitive results in comparison to its direct competitors, both in terms of predictive performance and model size. Compared to an HMC method that does not produce label partitions though, our method results in larger models on~average, while still producing equally large or smaller models in one third of the datasets by creating suitable label partitions.},
isbn = {978-3-030-67664-3},
langid = {english},
keywords = {Bi-clustering,Hierarchical multi-label classification,Predictive clustering trees},
organization = {MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES, 2021, Cham},
file = {/home/pd/Zotero/storage/LAN99SQM/Santos et al. - 2021 - Predictive Bi-clustering Trees for Hierarchical Mu.pdf}
}

@book{schafer1966introduction,
title = {An Introduction to Nonassociative Algebras},
author = {Schafer, Richard D.},
year = {1966},
publisher = {Academic Press},
address = {New York},
urldate = {15 Mar. 2024}
}

@article{schrynemackers2015classifying,
title = {Classifying Pairs with Trees for Supervised Biological Network Inference},
author = {Schrynemackers, Marie and Wehenkel, Louis and Babu, M Madan and Geurts, Pierre},
year = {2015},
journal = {Molecular BioSystems},
volume = {11},
number = {8},
pages = {2116--2125},
publisher = {Royal Society of Chemistry},
doi = {10.1039/c5mb00174a},
file = {/home/pd/Zotero/storage/DEUEP6HJ/Schrynemackers et al. - 2015 - Classifying pairs with trees for supervised biolog.pdf}
}

@inproceedings{tan2016improved,
title = {Improved Representation Learning for Question Answer Matching},
booktitle = {Proceedings [...]},
author = {Tan, Ming and Dos Santos, Cicero and Xiang, Bing and Zhou, Bowen},
year = {2016},
pages = {464--473},
publisher = {ACL},
address = {Berlin},
organization = {ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, 54, 2016, Berlin}
}

@article{tang2014making,
title = {Making Sense of Large-Scale Kinase Inhibitor Bioactivity Data Sets},
subtitle = {A Comparative and Integrative Analysis},
author = {Tang, Jing and Szwajda, Agnieszka and Shakyawar, Sushil and Xu, Tao and Hintsanen, Petteri and Wennerberg, Krister and Aittokallio, Tero},
year = {2014},
journal = {Journal of Chemical Information and Modeling},
volume = {54},
number = {3},
pages = {735--743},
publisher = {ACS Publications},
doi = {10.1021/ci400709d}
}

@article{teng2020npinter,
title = {{{NPInter}} v4. 0},
subtitle = {An Integrated Database of {{ncRNA}} Interactions},
author = {Teng, Xueyi and Chen, Xiaomin and Xue, Hua and Tang, Yiheng and Zhang, Peng and Kang, Quan and Hao, Yajing and Chen, Runsheng and Zhao, Yi and He, Shunmin},
year = {2020},
journal = {Nucleic acids research},
volume = {48},
number = {D1},
pages = {D160--D165},
publisher = {Oxford University Press}
}

@article{thafar2021dti2vec,
title = {{{DTi2Vec}}},
subtitle = {{{Drug}}--Target Interaction Prediction Using Network Embedding and Ensemble Learning},
shorttitle = {{{DTi2Vec}}},
author = {Thafar, Maha A. and Olayan, Rawan S. and Albaradei, Somayah and Bajic, Vladimir B. and Gojobori, Takashi and Essack, Magbubah and Gao, Xin},
year = {2021},
month = sep,
journal = {Journal of Cheminformatics},
volume = {13},
number = {1},
pages = {71},
issn = {1758-2946},
doi = {10.1186/s13321-021-00552-w},
url = {https://doi.org/10.1186/s13321-021-00552-w},
urldate = {22 Nov. 2023},
abstract = {Drug--target interaction (DTI) prediction is a crucial step in drug discovery and repositioning as it reduces experimental validation costs if done right. Thus, developing in-silico methods to predict potential DTI has become a competitive research niche, with one of its main focuses being improving the prediction accuracy. Using machine learning (ML) models for this task, specifically network-based approaches, is effective and has shown great advantages over the other computational methods. However, ML model development involves upstream hand-crafted feature extraction and other processes that impact prediction accuracy. Thus, network-based representation learning techniques that provide automated feature extraction combined with traditional ML classifiers dealing with downstream link prediction tasks may be better-suited paradigms. Here, we present such a method, DTi2Vec, which identifies DTIs using network representation learning and ensemble learning techniques. DTi2Vec constructs the heterogeneous network, and then it automatically generates features for each drug and target using the nodes embedding technique. DTi2Vec demonstrated its ability in drug--target link prediction compared to several state-of-the-art network-based methods, using four benchmark datasets and large-scale data compiled from DrugBank. DTi2Vec showed a statistically significant increase in the prediction performances in terms of AUPR. We verified the "novel" predicted DTIs using several databases and scientific literature. DTi2Vec is a simple yet effective method that provides high DTI prediction performance while being scalable and efficient in computation, translating into a powerful drug repositioning tool.},
keywords = {Cheminformatics,Drug repositioning,Drug-target interaction,Ensemble learning,Heterogeneous network,Link prediction,Network embedding,Random walk,Representation learning},
annotation = {20 citations (Crossref) [2023-11-22]},
file = {/home/pd/Zotero/storage/KXVF9ZEE/Thafar et al. - 2021 - DTi2Vec Drug–target interaction prediction using .pdf;/home/pd/Zotero/storage/4BBEVSTB/s13321-021-00552-w.html}
}

@article{tinkamho1998random,
title = {The Random Subspace Method for Constructing Decision Forests},
author = {{Tin Kam Ho}},
year = {Aug./1998},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
volume = {20},
number = {8},
pages = {832--844},
issn = {01628828},
doi = {10.1109/34.709601},
url = {http://ieeexplore.ieee.org/document/709601/},
urldate = {23 Sep. 2023},
annotation = {4272 citations (Crossref) [2023-09-23]},
file = {/home/pd/Zotero/storage/T4QDXYMR/Tin Kam Ho - 1998 - The random subspace method for constructing decisi.pdf}
}

@article{vanengelen2020survey,
title = {A Survey on Semi-Supervised Learning},
author = {{van Engelen}, Jesper E. and Hoos, Holger H.},
year = {2020},
month = feb,
journal = {Machine Learning},
volume = {109},
number = {2},
pages = {373--440},
issn = {1573-0565},
doi = {10.1007/s10994-019-05855-6},
url = {https://doi.org/10.1007/s10994-019-05855-6},
urldate = {15 Mar. 2024},
abstract = {Semi-supervised learning is the branch of machine learning concerned with using labelled as well as unlabelled data to perform certain learning tasks. Conceptually situated between supervised and unsupervised learning, it permits harnessing the large amounts of unlabelled data available in many use cases in combination with typically smaller sets of labelled data. In recent years, research in this area has followed the general trends observed in machine learning, with much attention directed at neural network-based models and generative learning. The literature on the topic has also expanded in volume and scope, now encompassing a broad spectrum of theory, algorithms and applications. However, no recent surveys exist to collect and organize this knowledge, impeding the ability of researchers and engineers alike to utilize it. Filling this void, we present an up-to-date overview of semi-supervised learning methods, covering earlier work as well as more recent advances. We focus primarily on semi-supervised classification, where the large majority of semi-supervised learning research takes place. Our survey aims to provide researchers and practitioners new to the field as well as more advanced readers with a solid understanding of the main approaches and algorithms developed over the past two decades, with an emphasis on the most prominent and currently relevant work. Furthermore, we propose a new taxonomy of semi-supervised classification algorithms, which sheds light on the different conceptual and methodological approaches for incorporating unlabelled data into the training process. Lastly, we show how the fundamental assumptions underlying most semi-supervised learning algorithms are closely connected to each other, and how they relate to the well-known semi-supervised clustering assumption.},
langid = {english},
keywords = {Classification,Machine learning,Semi-supervised learning},
annotation = {1213 citations (Crossref) [2024-03-15]},
file = {/home/pd/Zotero/storage/6P8PULWL/van Engelen and Hoos - 2020 - A survey on semi-supervised learning.pdf}
}

@article{vanlaarhoven2011gaussian,
title = {Gaussian Interaction Profile Kernels for Predicting Drug--Target Interaction},
author = {Van Laarhoven, Twan and Nabuurs, Sander B and Marchiori, Elena},
year = {2011},
journal = {Bioinformatics},
volume = {27},
number = {21},
pages = {3036--3043},
publisher = {Oxford University Press},
file = {/home/pd/Zotero/storage/G29MDZ3G/Van Laarhoven et al. - 2011 - Gaussian interaction profile kernels for predictin.pdf}
}

@misc{vert2008reconstruction,
title = {Reconstruction of Biological Networks by Supervised Machine Learning Approaches},
author = {Vert, Jean Philippe},
year = {2008},
month = sep,
number = {arXiv:0806.0215},
eprint = {0806.0215},
primaryclass = {q-bio},
url = {http://arxiv.org/abs/0806.0215},
urldate = {29 Aug. 2023},
abstract = {We review a recent trend in computational systems biology which aims at using pattern recognition algorithms to infer the structure of large-scale biological networks from heterogeneous genomic data. We present several strategies that have been proposed and that lead to different pattern recognition problems and algorithms. The strenght of these approaches is illustrated on the reconstruction of metabolic, protein-protein and regulatory networks of model organisms. In all cases, state-of-the-art performance is reported.},
archiveprefix = {arxiv},
keywords = {Quantitative Biology - Quantitative Methods},
file = {/home/pd/Zotero/storage/UEZUEVYL/Vert - 2008 - Reconstruction of biological networks by supervise.pdf;/home/pd/Zotero/storage/7AHFWMTT/0806.html}
}

@inproceedings{wang2020learninga,
title = {Learning from {{Weak-Label Data}}},
subtitle = {{{A Deep Forest Expedition}}},
shorttitle = {Learning from {{Weak-Label Data}}},
booktitle = {Proceedings [...]},
author = {Wang, Qian-Wei and Yang, Liang and Li, Yu-Feng},
year = {2020},
month = apr,
pages = {6251--6258},
address = {New York},
doi = {10.1609/aaai.v34i04.6092},
url = {https://doi.org/10.1609/aaai.v34i04.6092},
organization = {AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, 34, 2020, New York},
file = {/home/pd/Zotero/storage/SXHBBBEU/Wang et al. - 2020 - Learning from Weak-Label Data A Deep Forest Exped.pdf}
}

@article{wangsurvey,
title = {Survey of {{Similarity-Based Prediction}} of {{Drug-Protein Interactions}}},
author = {Wang, Chen and Kurgan, Lukasz},
journal = {Current Medicinal Chemistry},
volume = {27},
number = {35},
pages = {5856--5886},
url = {https://www.eurekaselect.com/article/100229},
urldate = {15 Mar. 2024},
abstract = {Therapeutic activity of a significant majority of drugs is determined by their interactions with proteins. Databases of drug-protein interactions (DPIs) primarily focus on the therapeutic protein targets while the knowledge of the off-targets is fragmented and partial. One way to bridge this knowledge gap is to employ computational methods to predict protein targets for a given drug molecule, or interacting drugs for given protein targets. We survey a comprehensive set of 35 methods that were published in high-impact venues and that predict DPIs based on similarity between drugs and similarity between protein targets. We analyze the internal databases of known PDIs that these methods utilize to compute similarities, and investigate how they are linked to the 12 publicly available source databases. We discuss contents, impact and relationships between these internal and source databases, and well as the timeline of their releases and publications. The 35 predictors exploit and often combine three types of similarities that consider drug structures, drug profiles, and target sequences. We review the predictive architectures of these methods, their impact, and we explain how their internal DPIs databases are linked to the source databases. We also include a detailed timeline of the development of these predictors and discuss the underlying limitations of the current resources and predictive tools. Finally, we provide several recommendations concerning the future development of the related databases and methods.},
langid = {english},
file = {/home/pd/Zotero/storage/KBSM6BLM/Wang and Kurgan - Survey of Similarity-Based Prediction of Drug-Prot.pdf}
}

@article{wu2006npinter,
title = {{{NPInter}}},
subtitle = {The Noncoding {{RNAs}} and Protein Related Biomacromolecules Interaction Database},
author = {Wu, Tao and Wang, Jie and Liu, Changning and Zhang, Yong and Shi, Baochen and Zhu, Xiaopeng and Zhang, Zhihua and Skogerb{\o}, Geir and Chen, Lan and Lu, Hongchao and others},
year = {2006},
journal = {Nucleic acids research},
volume = {34},
number = {suppl\_1},
pages = {D150--D152},
publisher = {Oxford University Press}
}

@article{yamanishi2008prediction,
title = {Prediction of Drug--Target Interaction Networks from the Integration of Chemical and Genomic Spaces},
author = {Yamanishi, Yoshihiro and Araki, Michihiro and Gutteridge, Alex and Honda, Wataru and Kanehisa, Minoru},
year = {2008},
journal = {Bioinformatics},
volume = {24},
number = {13},
pages = {i232--i240},
publisher = {Oxford University Press}
}

@article{yamanishi2010drugtarget,
title = {Drug-Target Interaction Prediction from Chemical, Genomic and Pharmacological Data in an Integrated Framework},
author = {Yamanishi, Yoshihiro and Kotera, Masaaki and Kanehisa, Minoru and Goto, Susumu},
year = {2010},
month = jun,
journal = {Bioinformatics},
volume = {26},
number = {12},
pages = {i246-i254},
issn = {1367-4803},
doi = {10.1093/bioinformatics/btq176},
url = {https://doi.org/10.1093/bioinformatics/btq176},
annotation = {359 citations (Crossref) [2023-08-29]}
}

@article{yu2020fpscdtia,
title = {{{FPSC-DTI}}},
subtitle = {Drug--Target Interaction Prediction Based on Feature Projection Fuzzy Classification and Super Cluster Fusion},
shorttitle = {{{FPSC-DTI}}},
author = {Yu, Donghua and Liu, Guojun and Zhao, Ning and Liu, Xiaoyan and Guo, Maozu},
year = {2020},
month = dec,
journal = {Molecular Omics},
volume = {16},
number = {6},
pages = {583--591},
publisher = {The Royal Society of Chemistry},
issn = {2515-4184},
doi = {10.1039/D0MO00062K},
url = {https://pubs.rsc.org/en/content/articlelanding/2020/mo/d0mo00062k},
urldate = {31 Oct. 2023},
abstract = {Identifying drug--target interactions (DTIs) is an important part of drug discovery and development. However, identifying DTIs is a complex process that is time consuming, costly, long, and often inefficient, with a low success rate, especially with wet-experimental methods. Computational methods based on drug repositioning and network pharmacology can effectively overcome these defects. In this paper, we develop a new fusion method, called FPSC-DTI, that fuses feature projection fuzzy classification (FP) and super cluster classification (SC) to predict DTI. As the experimental result, the mean percentile ranking (MPR) that was yielded by FPSC-DTI achieved 0.043, 0.084, 0.072, and 0.146 on enzyme, ion channel (IC), G-protein-coupled receptor (GPCR), and nuclear receptor (NR) datasets, respectively. And the AUC values exceeded 0.969 over all four datasets. Compared with other methods, FPSC-DTI obtained better predictive performance and became more robust.},
langid = {english},
annotation = {4 citations (Crossref) [2023-10-31]},
file = {/home/pd/Zotero/storage/6WW3IIGU/Yu et al. - 2020 - FPSC-DTI drug–target interaction prediction based.pdf;/home/pd/Zotero/storage/XXJKBNH8/Yu et al. - 2020 - FPSC-DTI drug–target interaction prediction based.pdf}
}

@article{zhang2007mlknn,
title = {{{ML-KNN}}},
subtitle = {{{A}} Lazy Learning Approach to Multi-Label Learning},
shorttitle = {{{ML-KNN}}},
author = {Zhang, Min-Ling and Zhou, Zhi-Hua},
year = {2007},
month = jul,
journal = {Pattern Recognition},
volume = {40},
number = {7},
pages = {2038--2048},
issn = {0031-3203},
doi = {10.1016/j.patcog.2006.12.019},
url = {https://www.sciencedirect.com/science/article/pii/S0031320307000027},
urldate = {23 Mar. 2024},
abstract = {Multi-label learning originated from the investigation of text categorization problem, where each document may belong to several predefined topics simultaneously. In multi-label learning, the training set is composed of instances each associated with a set of labels, and the task is to predict the label sets of unseen instances through analyzing training instances with known label sets. In this paper, a multi-label lazy learning approach named ML-KNN is presented, which is derived from the traditional K-nearest neighbor (KNN) algorithm. In detail, for each unseen instance, its K nearest neighbors in the training set are firstly identified. After that, based on statistical information gained from the label sets of these neighboring instances, i.e. the number of neighboring instances belonging to each possible class, maximum a posteriori (MAP) principle is utilized to determine the label set for the unseen instance. Experiments on three different real-world multi-label learning problems, i.e. Yeast gene functional analysis, natural scene classification and automatic web page categorization, show that ML-KNN achieves superior performance to some well-established multi-label learning algorithms.},
keywords = {-nearest neighbor,Functional genomics,Lazy learning,Machine learning,Multi-label learning,Natural scene classification,Text categorization},
annotation = {2418 citations (Crossref) [2024-03-23]},
file = {/home/pd/Zotero/storage/I7LJHRK6/Zhang and Zhou - 2007 - ML-KNN A lazy learning approach to multi-label le.pdf;/home/pd/Zotero/storage/JTHZVBMP/S0031320307000027.html}
}

@article{zhao2016noncode,
title = {{{NONCODE}} 2016},
subtitle = {An Informative and Valuable Data Source of Long Non-Coding {{RNAs}}},
shorttitle = {{{NONCODE}} 2016},
author = {Zhao, Yi and Li, Hui and Fang, Shuangsang and Kang, Yue and Wu, Wei and Hao, Yajing and Li, Ziyang and Bu, Dechao and Sun, Ninghui and Zhang, Michael Q.},
year = {2016},
journal = {Nucleic acids research},
volume = {44},
number = {D1},
pages = {D203--D208},
publisher = {Oxford University Press},
url = {https://academic.oup.com/nar/article-abstract/44/D1/D203/2503065},
urldate = {15 Mar. 2024},
file = {/home/pd/Zotero/storage/WMND95NK/2503065.html}
}

@article{zhou2018brief,
title = {A Brief Introduction to Weakly Supervised Learning},
author = {Zhou, Zhi-Hua},
year = {2018},
journal = {National science review},
volume = {5},
number = {1},
pages = {44--53},
publisher = {Oxford University Press}
}

@article{zhou2019deep,
title = {Deep Forest},
author = {Zhou, Zhi-Hua and Feng, Ji},
year = {2019},
month = jan,
journal = {National Science Review},
volume = {6},
number = {1},
pages = {74--86},
issn = {2095-5138},
doi = {10.1093/nsr/nwy108},
url = {https://doi.org/10.1093/nsr/nwy108},
urldate = {18 Dec. 2023},
abstract = {Current deep-learning models are mostly built upon neural networks, i.e. multiple layers of parameterized differentiable non-linear modules that can be trained by backpropagation. In this paper, we explore the possibility of building deep models based on non-differentiable modules such as decision trees. After a discussion about the mystery behind deep neural networks, particularly by contrasting them with shallow neural networks and traditional machine-learning techniques such as decision trees and boosting machines, we conjecture that the success of deep neural networks owes much to three characteristics, i.e. layer-by-layer processing, in-model feature transformation and sufficient model complexity. On one hand, our conjecture may offer inspiration for theoretical understanding of deep learning; on the other hand, to verify the conjecture, we propose an approach that generates deep forest holding these characteristics. This is a decision-tree ensemble approach, with fewer hyper-parameters than deep neural networks, and its model complexity can be automatically determined in a data-dependent way. Experiments show that its performance is quite robust to hyper-parameter settings, such that in most cases, even across different data from different domains, it is able to achieve excellent performance by using the same default setting. This study opens the door to deep learning based on non-differentiable modules without gradient-based adjustment, and exhibits the possibility of constructing deep models without backpropagation.},
annotation = {323 citations (Crossref) [2023-12-18]},
file = {/home/pd/Zotero/storage/FLGZNTY8/Zhou and Feng - 2019 - Deep forest.pdf;/home/pd/Zotero/storage/KUIT2NKQ/5123737.html}
}

@article{zhou2021progresses,
title = {Progresses and Challenges in Link Prediction},
author = {Zhou, Tao},
year = {2021},
journal = {Iscience},
volume = {24},
number = {11},
publisher = {Elsevier},
url = {https://www.cell.com/iscience/pdf/S2589-0042(21)01185-8.pdf},
urldate = {17 Mar. 2024},
file = {/home/pd/Zotero/storage/RBJJ8N7A/Zhou - 2021 - Progresses and challenges in link prediction.pdf}
}

@inbook{zhou2021semisupervised,
title = {Semi-{{Supervised Learning}}},
booktitle = {Machine {{Learning}}},
author = {Zhou, Zhi-Hua},
year = {2021},
pages = {315--341},
publisher = {Springer Singapore},
address = {Singapore},
doi = {10.1007/978-981-15-1967-3_13},
url = {https://link.springer.com/10.1007/978-981-15-1967-3_13},
urldate = {15 Mar. 2024},
collaborator = {Zhou, Zhi-Hua},
isbn = {9789811519666 9789811519673},
langid = {english}
}

@book{zhu2022introduction,
title = {Introduction to Semi-Supervised Learning},
author = {Zhu, Xiaojin and Goldberg, Andrew B.},
year = {2022},
publisher = {Springer Nature}
}
